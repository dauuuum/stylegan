{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stylegan2-Ada-Colab-Starter의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dauuuum/stylegan/blob/main/Stylegan2_Ada.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8VnyjDhiBQY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc06f286-4f45-4a06-fbdc-be74254bc5f5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-Etf334QxqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1b5545d-ff1d-4569-b65a-98de30830bb4"
      },
      "source": [
        "import zipfile\n",
        "path = \"/content/drive/MyDrive/\"\n",
        "dataset = \"train_final.zip\"\n",
        "local_path = \"my_data/\"\n",
        "file_name = path + dataset\n",
        "with zipfile.ZipFile(file_name, 'r') as zip:\n",
        "   #zip.printdir()\n",
        "   print('Extracting all the files now...') \n",
        "   zip.extractall(local_path) \n",
        "   print('Done!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting all the files now...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCp-pnotL8R0"
      },
      "source": [
        "Pull the latest version of stylegan2-ada from github,\n",
        "\n",
        "Use the right version of TF And make sure we can talk to the colab gpu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzDuIoMcqfBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b6dc01-cc34-4f26-c529-c2885b699c52"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Download the code\n",
        "!git clone https://github.com/NVlabs/stylegan2-ada.git\n",
        "%cd stylegan2-ada\n",
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        "\n",
        "print('Tensorflow version: {}'.format(tf.__version__) )\n",
        "!nvidia-smi -L\n",
        "print('GPU Identified at: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Cloning into 'stylegan2-ada'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 74 (delta 0), reused 1 (delta 0), pack-reused 71\u001b[K\n",
            "Unpacking objects: 100% (74/74), done.\n",
            "/content/stylegan2-ada\n",
            "\u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Ktest_nvcc.cu: No such file or directory\n",
            "\u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K-x c++\u001b[m\u001b[K’ after last input file has no effect\n",
            "\u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[Kno input files\n",
            "compilation terminated.\n",
            "Tensorflow version: 1.15.2\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-b2640c2e-219e-e6e1-5a08-9127160bc4dd)\n",
            "GPU Identified at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umKaTRK4dlL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ba04486-b048-46f0-a348-e7c366b0dba9"
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAgPsEMjMVeE"
      },
      "source": [
        "# Download Weights for Transfer Learning\n",
        "\n",
        "1024x1024 : http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNw6T-DZJjHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "062e1d47-138c-4363-d8e7-7c9859387750"
      },
      "source": [
        "!wget http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-09 13:55:07--  http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\n",
            "Resolving d36zk2xti64re0.cloudfront.net (d36zk2xti64re0.cloudfront.net)... 13.226.70.44, 13.226.70.54, 13.226.70.39, ...\n",
            "Connecting to d36zk2xti64re0.cloudfront.net (d36zk2xti64re0.cloudfront.net)|13.226.70.44|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 381673535 (364M) [application/x-www-form-urlencoded]\n",
            "Saving to: ‘stylegan2-ffhq-config-f.pkl’\n",
            "\n",
            "stylegan2-ffhq-conf 100%[===================>] 363.99M  26.6MB/s    in 18s     \n",
            "\n",
            "2021-11-09 13:55:27 (19.8 MB/s) - ‘stylegan2-ffhq-config-f.pkl’ saved [381673535/381673535]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiQhCDuI5UP8"
      },
      "source": [
        "# Do some surgery when weights don't exist for your specific resolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMB43NnS5TCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58f0e7a4-fe2e-4972-d87a-6c106c1ef59a"
      },
      "source": [
        "!git clone https://github.com/aydao/stylegan2-surgery.git\n",
        "%cd stylegan2-surgery"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan2-surgery'...\n",
            "remote: Enumerating objects: 1557, done.\u001b[K\n",
            "remote: Total 1557 (delta 0), reused 0 (delta 0), pack-reused 1557\u001b[K\n",
            "Receiving objects: 100% (1557/1557), 17.03 MiB | 14.69 MiB/s, done.\n",
            "Resolving deltas: 100% (1073/1073), done.\n",
            "/content/stylegan2-surgery\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeujsXX2AigK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c4d4de-b38a-43c3-ce22-7f527d34a931"
      },
      "source": [
        "!python create_initial_network_pkl.py --width 256 --height 256"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Local submit - run_dir: .\n",
            "dnnlib: Running training.diagnostic.create_initial_pkl() on localhost...\n",
            "Constructing networks...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Compiling... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Compiling... Loading... Done.\n",
            "\n",
            "G                             Params    OutputShape         WeightShape     \n",
            "---                           ---       ---                 ---             \n",
            "latents_in                    -         (?, 512)            -               \n",
            "labels_in                     -         (?, 0)              -               \n",
            "lod                           -         ()                  -               \n",
            "dlatent_avg                   -         (512,)              -               \n",
            "G_mapping/latents_in          -         (?, 512)            -               \n",
            "G_mapping/labels_in           -         (?, 0)              -               \n",
            "G_mapping/Normalize           -         (?, 512)            -               \n",
            "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense2              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense3              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense4              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense5              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense6              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense7              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Broadcast           -         (?, 14, 512)        -               \n",
            "G_mapping/dlatents_out        -         (?, 14, 512)        -               \n",
            "Truncation/Lerp               -         (?, 14, 512)        -               \n",
            "G_synthesis/dlatents_in       -         (?, 14, 512)        -               \n",
            "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
            "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
            "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
            "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
            "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
            "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
            "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
            "G_synthesis/64x64/Conv0_up    2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Conv1       2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
            "G_synthesis/64x64/ToRGB       264195    (?, 3, 64, 64)      (1, 1, 512, 3)  \n",
            "G_synthesis/128x128/Conv0_up  1442561   (?, 256, 128, 128)  (3, 3, 512, 256)\n",
            "G_synthesis/128x128/Conv1     721409    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
            "G_synthesis/128x128/ToRGB     132099    (?, 3, 128, 128)    (1, 1, 256, 3)  \n",
            "G_synthesis/256x256/Conv0_up  426369    (?, 128, 256, 256)  (3, 3, 256, 128)\n",
            "G_synthesis/256x256/Conv1     213249    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
            "G_synthesis/256x256/Upsample  -         (?, 3, 256, 256)    -               \n",
            "G_synthesis/256x256/ToRGB     66051     (?, 3, 256, 256)    (1, 1, 128, 3)  \n",
            "G_synthesis/images_out        -         (?, 3, 256, 256)    -               \n",
            "G_synthesis/noise0            -         (1, 1, 4, 4)        -               \n",
            "G_synthesis/noise1            -         (1, 1, 8, 8)        -               \n",
            "G_synthesis/noise2            -         (1, 1, 8, 8)        -               \n",
            "G_synthesis/noise3            -         (1, 1, 16, 16)      -               \n",
            "G_synthesis/noise4            -         (1, 1, 16, 16)      -               \n",
            "G_synthesis/noise5            -         (1, 1, 32, 32)      -               \n",
            "G_synthesis/noise6            -         (1, 1, 32, 32)      -               \n",
            "G_synthesis/noise7            -         (1, 1, 64, 64)      -               \n",
            "G_synthesis/noise8            -         (1, 1, 64, 64)      -               \n",
            "G_synthesis/noise9            -         (1, 1, 128, 128)    -               \n",
            "G_synthesis/noise10           -         (1, 1, 128, 128)    -               \n",
            "G_synthesis/noise11           -         (1, 1, 256, 256)    -               \n",
            "G_synthesis/noise12           -         (1, 1, 256, 256)    -               \n",
            "images_out                    -         (?, 3, 256, 256)    -               \n",
            "---                           ---       ---                 ---             \n",
            "Total                         30034338                                      \n",
            "\n",
            "\n",
            "D                    Params    OutputShape         WeightShape     \n",
            "---                  ---       ---                 ---             \n",
            "images_in            -         (?, 3, 256, 256)    -               \n",
            "labels_in            -         (?, 0)              -               \n",
            "256x256/FromRGB      512       (?, 128, 256, 256)  (1, 1, 3, 128)  \n",
            "256x256/Conv0        147584    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
            "256x256/Conv1_down   295168    (?, 256, 128, 128)  (3, 3, 128, 256)\n",
            "256x256/Skip         32768     (?, 256, 128, 128)  (1, 1, 128, 256)\n",
            "128x128/Conv0        590080    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "128x128/Conv1_down   1180160   (?, 512, 64, 64)    (3, 3, 256, 512)\n",
            "128x128/Skip         131072    (?, 512, 64, 64)    (1, 1, 256, 512)\n",
            "64x64/Conv0          2359808   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "64x64/Conv1_down     2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "64x64/Skip           262144    (?, 512, 32, 32)    (1, 1, 512, 512)\n",
            "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
            "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
            "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
            "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
            "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
            "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
            "Output               513       (?, 1)              (512, 1)        \n",
            "scores_out           -         (?, 1)              -               \n",
            "---                  ---       ---                 ---             \n",
            "Total                28864129                                      \n",
            "\n",
            "Saving network-initial-config-f-256x256-0.pkl\n",
            "dnnlib: Finished training.diagnostic.create_initial_pkl() in 37s.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-67aZRy4BXL6"
      },
      "source": [
        "### Copying Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD11yooa8Znt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc540837-00d1-4580-bff6-56e307b51f80"
      },
      "source": [
        "!python copy_weights.py /content/stylegan2-ffhq-config-f.pkl /content/stylegan2-surgery/network-initial-config-f-256x256-0.pkl --output_pkl /content/surgery_output.pkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Loading... Done.\n",
            "Source:\n",
            "\n",
            "G                               Params    OutputShape          WeightShape     \n",
            "---                             ---       ---                  ---             \n",
            "latents_in                      -         (?, 512)             -               \n",
            "labels_in                       -         (?, 0)               -               \n",
            "lod                             -         ()                   -               \n",
            "dlatent_avg                     -         (512,)               -               \n",
            "G_mapping/latents_in            -         (?, 512)             -               \n",
            "G_mapping/labels_in             -         (?, 0)               -               \n",
            "G_mapping/Normalize             -         (?, 512)             -               \n",
            "G_mapping/Dense0                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense1                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense2                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense3                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense4                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense5                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense6                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense7                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Broadcast             -         (?, 18, 512)         -               \n",
            "G_mapping/dlatents_out          -         (?, 18, 512)         -               \n",
            "Truncation/Lerp                 -         (?, 18, 512)         -               \n",
            "G_synthesis/dlatents_in         -         (?, 18, 512)         -               \n",
            "G_synthesis/4x4/Const           8192      (?, 512, 4, 4)       (1, 512, 4, 4)  \n",
            "G_synthesis/4x4/Conv            2622465   (?, 512, 4, 4)       (3, 3, 512, 512)\n",
            "G_synthesis/4x4/ToRGB           264195    (?, 3, 4, 4)         (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up        2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1           2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Upsample        -         (?, 3, 8, 8)         -               \n",
            "G_synthesis/8x8/ToRGB           264195    (?, 3, 8, 8)         (1, 1, 512, 3)  \n",
            "G_synthesis/16x16/Conv0_up      2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1         2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Upsample      -         (?, 3, 16, 16)       -               \n",
            "G_synthesis/16x16/ToRGB         264195    (?, 3, 16, 16)       (1, 1, 512, 3)  \n",
            "G_synthesis/32x32/Conv0_up      2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1         2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Upsample      -         (?, 3, 32, 32)       -               \n",
            "G_synthesis/32x32/ToRGB         264195    (?, 3, 32, 32)       (1, 1, 512, 3)  \n",
            "G_synthesis/64x64/Conv0_up      2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Conv1         2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Upsample      -         (?, 3, 64, 64)       -               \n",
            "G_synthesis/64x64/ToRGB         264195    (?, 3, 64, 64)       (1, 1, 512, 3)  \n",
            "G_synthesis/128x128/Conv0_up    1442561   (?, 256, 128, 128)   (3, 3, 512, 256)\n",
            "G_synthesis/128x128/Conv1       721409    (?, 256, 128, 128)   (3, 3, 256, 256)\n",
            "G_synthesis/128x128/Upsample    -         (?, 3, 128, 128)     -               \n",
            "G_synthesis/128x128/ToRGB       132099    (?, 3, 128, 128)     (1, 1, 256, 3)  \n",
            "G_synthesis/256x256/Conv0_up    426369    (?, 128, 256, 256)   (3, 3, 256, 128)\n",
            "G_synthesis/256x256/Conv1       213249    (?, 128, 256, 256)   (3, 3, 128, 128)\n",
            "G_synthesis/256x256/Upsample    -         (?, 3, 256, 256)     -               \n",
            "G_synthesis/256x256/ToRGB       66051     (?, 3, 256, 256)     (1, 1, 128, 3)  \n",
            "G_synthesis/512x512/Conv0_up    139457    (?, 64, 512, 512)    (3, 3, 128, 64) \n",
            "G_synthesis/512x512/Conv1       69761     (?, 64, 512, 512)    (3, 3, 64, 64)  \n",
            "G_synthesis/512x512/Upsample    -         (?, 3, 512, 512)     -               \n",
            "G_synthesis/512x512/ToRGB       33027     (?, 3, 512, 512)     (1, 1, 64, 3)   \n",
            "G_synthesis/1024x1024/Conv0_up  51297     (?, 32, 1024, 1024)  (3, 3, 64, 32)  \n",
            "G_synthesis/1024x1024/Conv1     25665     (?, 32, 1024, 1024)  (3, 3, 32, 32)  \n",
            "G_synthesis/1024x1024/Upsample  -         (?, 3, 1024, 1024)   -               \n",
            "G_synthesis/1024x1024/ToRGB     16515     (?, 3, 1024, 1024)   (1, 1, 32, 3)   \n",
            "G_synthesis/images_out          -         (?, 3, 1024, 1024)   -               \n",
            "G_synthesis/noise0              -         (1, 1, 4, 4)         -               \n",
            "G_synthesis/noise1              -         (1, 1, 8, 8)         -               \n",
            "G_synthesis/noise2              -         (1, 1, 8, 8)         -               \n",
            "G_synthesis/noise3              -         (1, 1, 16, 16)       -               \n",
            "G_synthesis/noise4              -         (1, 1, 16, 16)       -               \n",
            "G_synthesis/noise5              -         (1, 1, 32, 32)       -               \n",
            "G_synthesis/noise6              -         (1, 1, 32, 32)       -               \n",
            "G_synthesis/noise7              -         (1, 1, 64, 64)       -               \n",
            "G_synthesis/noise8              -         (1, 1, 64, 64)       -               \n",
            "G_synthesis/noise9              -         (1, 1, 128, 128)     -               \n",
            "G_synthesis/noise10             -         (1, 1, 128, 128)     -               \n",
            "G_synthesis/noise11             -         (1, 1, 256, 256)     -               \n",
            "G_synthesis/noise12             -         (1, 1, 256, 256)     -               \n",
            "G_synthesis/noise13             -         (1, 1, 512, 512)     -               \n",
            "G_synthesis/noise14             -         (1, 1, 512, 512)     -               \n",
            "G_synthesis/noise15             -         (1, 1, 1024, 1024)   -               \n",
            "G_synthesis/noise16             -         (1, 1, 1024, 1024)   -               \n",
            "images_out                      -         (?, 3, 1024, 1024)   -               \n",
            "---                             ---       ---                  ---             \n",
            "Total                           30370060                                       \n",
            "\n",
            "\n",
            "D                     Params    OutputShape          WeightShape     \n",
            "---                   ---       ---                  ---             \n",
            "images_in             -         (?, 3, 1024, 1024)   -               \n",
            "labels_in             -         (?, 0)               -               \n",
            "1024x1024/FromRGB     128       (?, 32, 1024, 1024)  (1, 1, 3, 32)   \n",
            "1024x1024/Conv0       9248      (?, 32, 1024, 1024)  (3, 3, 32, 32)  \n",
            "1024x1024/Conv1_down  18496     (?, 64, 512, 512)    (3, 3, 32, 64)  \n",
            "1024x1024/Skip        2048      (?, 64, 512, 512)    (1, 1, 32, 64)  \n",
            "512x512/Conv0         36928     (?, 64, 512, 512)    (3, 3, 64, 64)  \n",
            "512x512/Conv1_down    73856     (?, 128, 256, 256)   (3, 3, 64, 128) \n",
            "512x512/Skip          8192      (?, 128, 256, 256)   (1, 1, 64, 128) \n",
            "256x256/Conv0         147584    (?, 128, 256, 256)   (3, 3, 128, 128)\n",
            "256x256/Conv1_down    295168    (?, 256, 128, 128)   (3, 3, 128, 256)\n",
            "256x256/Skip          32768     (?, 256, 128, 128)   (1, 1, 128, 256)\n",
            "128x128/Conv0         590080    (?, 256, 128, 128)   (3, 3, 256, 256)\n",
            "128x128/Conv1_down    1180160   (?, 512, 64, 64)     (3, 3, 256, 512)\n",
            "128x128/Skip          131072    (?, 512, 64, 64)     (1, 1, 256, 512)\n",
            "64x64/Conv0           2359808   (?, 512, 64, 64)     (3, 3, 512, 512)\n",
            "64x64/Conv1_down      2359808   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "64x64/Skip            262144    (?, 512, 32, 32)     (1, 1, 512, 512)\n",
            "32x32/Conv0           2359808   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "32x32/Conv1_down      2359808   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "32x32/Skip            262144    (?, 512, 16, 16)     (1, 1, 512, 512)\n",
            "16x16/Conv0           2359808   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "16x16/Conv1_down      2359808   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "16x16/Skip            262144    (?, 512, 8, 8)       (1, 1, 512, 512)\n",
            "8x8/Conv0             2359808   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "8x8/Conv1_down        2359808   (?, 512, 4, 4)       (3, 3, 512, 512)\n",
            "8x8/Skip              262144    (?, 512, 4, 4)       (1, 1, 512, 512)\n",
            "4x4/MinibatchStddev   -         (?, 513, 4, 4)       -               \n",
            "4x4/Conv              2364416   (?, 512, 4, 4)       (3, 3, 513, 512)\n",
            "4x4/Dense0            4194816   (?, 512)             (8192, 512)     \n",
            "Output                513       (?, 1)               (512, 1)        \n",
            "scores_out            -         (?, 1)               -               \n",
            "---                   ---       ---                  ---             \n",
            "Total                 29012513                                       \n",
            "\n",
            "\n",
            "Gs                              Params    OutputShape          WeightShape     \n",
            "---                             ---       ---                  ---             \n",
            "latents_in                      -         (?, 512)             -               \n",
            "labels_in                       -         (?, 0)               -               \n",
            "lod                             -         ()                   -               \n",
            "dlatent_avg                     -         (512,)               -               \n",
            "G_mapping/latents_in            -         (?, 512)             -               \n",
            "G_mapping/labels_in             -         (?, 0)               -               \n",
            "G_mapping/Normalize             -         (?, 512)             -               \n",
            "G_mapping/Dense0                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense1                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense2                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense3                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense4                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense5                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense6                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense7                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Broadcast             -         (?, 18, 512)         -               \n",
            "G_mapping/dlatents_out          -         (?, 18, 512)         -               \n",
            "Truncation/Lerp                 -         (?, 18, 512)         -               \n",
            "G_synthesis/dlatents_in         -         (?, 18, 512)         -               \n",
            "G_synthesis/4x4/Const           8192      (?, 512, 4, 4)       (1, 512, 4, 4)  \n",
            "G_synthesis/4x4/Conv            2622465   (?, 512, 4, 4)       (3, 3, 512, 512)\n",
            "G_synthesis/4x4/ToRGB           264195    (?, 3, 4, 4)         (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up        2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1           2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Upsample        -         (?, 3, 8, 8)         -               \n",
            "G_synthesis/8x8/ToRGB           264195    (?, 3, 8, 8)         (1, 1, 512, 3)  \n",
            "G_synthesis/16x16/Conv0_up      2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1         2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Upsample      -         (?, 3, 16, 16)       -               \n",
            "G_synthesis/16x16/ToRGB         264195    (?, 3, 16, 16)       (1, 1, 512, 3)  \n",
            "G_synthesis/32x32/Conv0_up      2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1         2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Upsample      -         (?, 3, 32, 32)       -               \n",
            "G_synthesis/32x32/ToRGB         264195    (?, 3, 32, 32)       (1, 1, 512, 3)  \n",
            "G_synthesis/64x64/Conv0_up      2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Conv1         2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Upsample      -         (?, 3, 64, 64)       -               \n",
            "G_synthesis/64x64/ToRGB         264195    (?, 3, 64, 64)       (1, 1, 512, 3)  \n",
            "G_synthesis/128x128/Conv0_up    1442561   (?, 256, 128, 128)   (3, 3, 512, 256)\n",
            "G_synthesis/128x128/Conv1       721409    (?, 256, 128, 128)   (3, 3, 256, 256)\n",
            "G_synthesis/128x128/Upsample    -         (?, 3, 128, 128)     -               \n",
            "G_synthesis/128x128/ToRGB       132099    (?, 3, 128, 128)     (1, 1, 256, 3)  \n",
            "G_synthesis/256x256/Conv0_up    426369    (?, 128, 256, 256)   (3, 3, 256, 128)\n",
            "G_synthesis/256x256/Conv1       213249    (?, 128, 256, 256)   (3, 3, 128, 128)\n",
            "G_synthesis/256x256/Upsample    -         (?, 3, 256, 256)     -               \n",
            "G_synthesis/256x256/ToRGB       66051     (?, 3, 256, 256)     (1, 1, 128, 3)  \n",
            "G_synthesis/512x512/Conv0_up    139457    (?, 64, 512, 512)    (3, 3, 128, 64) \n",
            "G_synthesis/512x512/Conv1       69761     (?, 64, 512, 512)    (3, 3, 64, 64)  \n",
            "G_synthesis/512x512/Upsample    -         (?, 3, 512, 512)     -               \n",
            "G_synthesis/512x512/ToRGB       33027     (?, 3, 512, 512)     (1, 1, 64, 3)   \n",
            "G_synthesis/1024x1024/Conv0_up  51297     (?, 32, 1024, 1024)  (3, 3, 64, 32)  \n",
            "G_synthesis/1024x1024/Conv1     25665     (?, 32, 1024, 1024)  (3, 3, 32, 32)  \n",
            "G_synthesis/1024x1024/Upsample  -         (?, 3, 1024, 1024)   -               \n",
            "G_synthesis/1024x1024/ToRGB     16515     (?, 3, 1024, 1024)   (1, 1, 32, 3)   \n",
            "G_synthesis/images_out          -         (?, 3, 1024, 1024)   -               \n",
            "G_synthesis/noise0              -         (1, 1, 4, 4)         -               \n",
            "G_synthesis/noise1              -         (1, 1, 8, 8)         -               \n",
            "G_synthesis/noise2              -         (1, 1, 8, 8)         -               \n",
            "G_synthesis/noise3              -         (1, 1, 16, 16)       -               \n",
            "G_synthesis/noise4              -         (1, 1, 16, 16)       -               \n",
            "G_synthesis/noise5              -         (1, 1, 32, 32)       -               \n",
            "G_synthesis/noise6              -         (1, 1, 32, 32)       -               \n",
            "G_synthesis/noise7              -         (1, 1, 64, 64)       -               \n",
            "G_synthesis/noise8              -         (1, 1, 64, 64)       -               \n",
            "G_synthesis/noise9              -         (1, 1, 128, 128)     -               \n",
            "G_synthesis/noise10             -         (1, 1, 128, 128)     -               \n",
            "G_synthesis/noise11             -         (1, 1, 256, 256)     -               \n",
            "G_synthesis/noise12             -         (1, 1, 256, 256)     -               \n",
            "G_synthesis/noise13             -         (1, 1, 512, 512)     -               \n",
            "G_synthesis/noise14             -         (1, 1, 512, 512)     -               \n",
            "G_synthesis/noise15             -         (1, 1, 1024, 1024)   -               \n",
            "G_synthesis/noise16             -         (1, 1, 1024, 1024)   -               \n",
            "images_out                      -         (?, 3, 1024, 1024)   -               \n",
            "---                             ---       ---                  ---             \n",
            "Total                           30370060                                       \n",
            "\n",
            "Target:\n",
            "\n",
            "G                             Params    OutputShape         WeightShape     \n",
            "---                           ---       ---                 ---             \n",
            "latents_in                    -         (?, 512)            -               \n",
            "labels_in                     -         (?, 0)              -               \n",
            "lod                           -         ()                  -               \n",
            "dlatent_avg                   -         (512,)              -               \n",
            "G_mapping/latents_in          -         (?, 512)            -               \n",
            "G_mapping/labels_in           -         (?, 0)              -               \n",
            "G_mapping/Normalize           -         (?, 512)            -               \n",
            "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense2              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense3              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense4              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense5              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense6              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense7              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Broadcast           -         (?, 14, 512)        -               \n",
            "G_mapping/dlatents_out        -         (?, 14, 512)        -               \n",
            "Truncation/Lerp               -         (?, 14, 512)        -               \n",
            "G_synthesis/dlatents_in       -         (?, 14, 512)        -               \n",
            "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
            "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
            "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
            "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
            "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
            "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
            "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
            "G_synthesis/64x64/Conv0_up    2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Conv1       2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
            "G_synthesis/64x64/ToRGB       264195    (?, 3, 64, 64)      (1, 1, 512, 3)  \n",
            "G_synthesis/128x128/Conv0_up  1442561   (?, 256, 128, 128)  (3, 3, 512, 256)\n",
            "G_synthesis/128x128/Conv1     721409    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
            "G_synthesis/128x128/ToRGB     132099    (?, 3, 128, 128)    (1, 1, 256, 3)  \n",
            "G_synthesis/256x256/Conv0_up  426369    (?, 128, 256, 256)  (3, 3, 256, 128)\n",
            "G_synthesis/256x256/Conv1     213249    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
            "G_synthesis/256x256/Upsample  -         (?, 3, 256, 256)    -               \n",
            "G_synthesis/256x256/ToRGB     66051     (?, 3, 256, 256)    (1, 1, 128, 3)  \n",
            "G_synthesis/images_out        -         (?, 3, 256, 256)    -               \n",
            "G_synthesis/noise0            -         (1, 1, 4, 4)        -               \n",
            "G_synthesis/noise1            -         (1, 1, 8, 8)        -               \n",
            "G_synthesis/noise2            -         (1, 1, 8, 8)        -               \n",
            "G_synthesis/noise3            -         (1, 1, 16, 16)      -               \n",
            "G_synthesis/noise4            -         (1, 1, 16, 16)      -               \n",
            "G_synthesis/noise5            -         (1, 1, 32, 32)      -               \n",
            "G_synthesis/noise6            -         (1, 1, 32, 32)      -               \n",
            "G_synthesis/noise7            -         (1, 1, 64, 64)      -               \n",
            "G_synthesis/noise8            -         (1, 1, 64, 64)      -               \n",
            "G_synthesis/noise9            -         (1, 1, 128, 128)    -               \n",
            "G_synthesis/noise10           -         (1, 1, 128, 128)    -               \n",
            "G_synthesis/noise11           -         (1, 1, 256, 256)    -               \n",
            "G_synthesis/noise12           -         (1, 1, 256, 256)    -               \n",
            "images_out                    -         (?, 3, 256, 256)    -               \n",
            "---                           ---       ---                 ---             \n",
            "Total                         30034338                                      \n",
            "\n",
            "\n",
            "D                    Params    OutputShape         WeightShape     \n",
            "---                  ---       ---                 ---             \n",
            "images_in            -         (?, 3, 256, 256)    -               \n",
            "labels_in            -         (?, 0)              -               \n",
            "256x256/FromRGB      512       (?, 128, 256, 256)  (1, 1, 3, 128)  \n",
            "256x256/Conv0        147584    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
            "256x256/Conv1_down   295168    (?, 256, 128, 128)  (3, 3, 128, 256)\n",
            "256x256/Skip         32768     (?, 256, 128, 128)  (1, 1, 128, 256)\n",
            "128x128/Conv0        590080    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "128x128/Conv1_down   1180160   (?, 512, 64, 64)    (3, 3, 256, 512)\n",
            "128x128/Skip         131072    (?, 512, 64, 64)    (1, 1, 256, 512)\n",
            "64x64/Conv0          2359808   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "64x64/Conv1_down     2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "64x64/Skip           262144    (?, 512, 32, 32)    (1, 1, 512, 512)\n",
            "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
            "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
            "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
            "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
            "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
            "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
            "Output               513       (?, 1)              (512, 1)        \n",
            "scores_out           -         (?, 1)              -               \n",
            "---                  ---       ---                 ---             \n",
            "Total                28864129                                      \n",
            "\n",
            "\n",
            "Gs                            Params    OutputShape         WeightShape     \n",
            "---                           ---       ---                 ---             \n",
            "latents_in                    -         (?, 512)            -               \n",
            "labels_in                     -         (?, 0)              -               \n",
            "lod                           -         ()                  -               \n",
            "dlatent_avg                   -         (512,)              -               \n",
            "G_mapping/latents_in          -         (?, 512)            -               \n",
            "G_mapping/labels_in           -         (?, 0)              -               \n",
            "G_mapping/Normalize           -         (?, 512)            -               \n",
            "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense2              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense3              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense4              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense5              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense6              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense7              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Broadcast           -         (?, 14, 512)        -               \n",
            "G_mapping/dlatents_out        -         (?, 14, 512)        -               \n",
            "Truncation/Lerp               -         (?, 14, 512)        -               \n",
            "G_synthesis/dlatents_in       -         (?, 14, 512)        -               \n",
            "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
            "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
            "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
            "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
            "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
            "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
            "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
            "G_synthesis/64x64/Conv0_up    2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Conv1       2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
            "G_synthesis/64x64/ToRGB       264195    (?, 3, 64, 64)      (1, 1, 512, 3)  \n",
            "G_synthesis/128x128/Conv0_up  1442561   (?, 256, 128, 128)  (3, 3, 512, 256)\n",
            "G_synthesis/128x128/Conv1     721409    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
            "G_synthesis/128x128/ToRGB     132099    (?, 3, 128, 128)    (1, 1, 256, 3)  \n",
            "G_synthesis/256x256/Conv0_up  426369    (?, 128, 256, 256)  (3, 3, 256, 128)\n",
            "G_synthesis/256x256/Conv1     213249    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
            "G_synthesis/256x256/Upsample  -         (?, 3, 256, 256)    -               \n",
            "G_synthesis/256x256/ToRGB     66051     (?, 3, 256, 256)    (1, 1, 128, 3)  \n",
            "G_synthesis/images_out        -         (?, 3, 256, 256)    -               \n",
            "G_synthesis/noise0            -         (1, 1, 4, 4)        -               \n",
            "G_synthesis/noise1            -         (1, 1, 8, 8)        -               \n",
            "G_synthesis/noise2            -         (1, 1, 8, 8)        -               \n",
            "G_synthesis/noise3            -         (1, 1, 16, 16)      -               \n",
            "G_synthesis/noise4            -         (1, 1, 16, 16)      -               \n",
            "G_synthesis/noise5            -         (1, 1, 32, 32)      -               \n",
            "G_synthesis/noise6            -         (1, 1, 32, 32)      -               \n",
            "G_synthesis/noise7            -         (1, 1, 64, 64)      -               \n",
            "G_synthesis/noise8            -         (1, 1, 64, 64)      -               \n",
            "G_synthesis/noise9            -         (1, 1, 128, 128)    -               \n",
            "G_synthesis/noise10           -         (1, 1, 128, 128)    -               \n",
            "G_synthesis/noise11           -         (1, 1, 256, 256)    -               \n",
            "G_synthesis/noise12           -         (1, 1, 256, 256)    -               \n",
            "images_out                    -         (?, 3, 256, 256)    -               \n",
            "---                           ---       ---                 ---             \n",
            "Total                         30034338                                      \n",
            "\n",
            "Restoring: G_synthesis/4x4/Const/const\n",
            "Restoring: G_synthesis/4x4/Conv/weight\n",
            "Restoring: G_synthesis/4x4/Conv/mod_weight\n",
            "Restoring: G_synthesis/4x4/Conv/mod_bias\n",
            "Restoring: G_synthesis/4x4/Conv/noise_strength\n",
            "Restoring: G_synthesis/4x4/Conv/bias\n",
            "Restoring: G_synthesis/4x4/ToRGB/weight\n",
            "Restoring: G_synthesis/4x4/ToRGB/mod_weight\n",
            "Restoring: G_synthesis/4x4/ToRGB/mod_bias\n",
            "Restoring: G_synthesis/4x4/ToRGB/bias\n",
            "Restoring: G_synthesis/8x8/Conv0_up/weight\n",
            "Restoring: G_synthesis/8x8/Conv0_up/mod_weight\n",
            "Restoring: G_synthesis/8x8/Conv0_up/mod_bias\n",
            "Restoring: G_synthesis/8x8/Conv0_up/noise_strength\n",
            "Restoring: G_synthesis/8x8/Conv0_up/bias\n",
            "Restoring: G_synthesis/8x8/Conv1/weight\n",
            "Restoring: G_synthesis/8x8/Conv1/mod_weight\n",
            "Restoring: G_synthesis/8x8/Conv1/mod_bias\n",
            "Restoring: G_synthesis/8x8/Conv1/noise_strength\n",
            "Restoring: G_synthesis/8x8/Conv1/bias\n",
            "Restoring: G_synthesis/8x8/ToRGB/weight\n",
            "Restoring: G_synthesis/8x8/ToRGB/mod_weight\n",
            "Restoring: G_synthesis/8x8/ToRGB/mod_bias\n",
            "Restoring: G_synthesis/8x8/ToRGB/bias\n",
            "Restoring: G_synthesis/16x16/Conv0_up/weight\n",
            "Restoring: G_synthesis/16x16/Conv0_up/mod_weight\n",
            "Restoring: G_synthesis/16x16/Conv0_up/mod_bias\n",
            "Restoring: G_synthesis/16x16/Conv0_up/noise_strength\n",
            "Restoring: G_synthesis/16x16/Conv0_up/bias\n",
            "Restoring: G_synthesis/16x16/Conv1/weight\n",
            "Restoring: G_synthesis/16x16/Conv1/mod_weight\n",
            "Restoring: G_synthesis/16x16/Conv1/mod_bias\n",
            "Restoring: G_synthesis/16x16/Conv1/noise_strength\n",
            "Restoring: G_synthesis/16x16/Conv1/bias\n",
            "Restoring: G_synthesis/16x16/ToRGB/weight\n",
            "Restoring: G_synthesis/16x16/ToRGB/mod_weight\n",
            "Restoring: G_synthesis/16x16/ToRGB/mod_bias\n",
            "Restoring: G_synthesis/16x16/ToRGB/bias\n",
            "Restoring: G_synthesis/32x32/Conv0_up/weight\n",
            "Restoring: G_synthesis/32x32/Conv0_up/mod_weight\n",
            "Restoring: G_synthesis/32x32/Conv0_up/mod_bias\n",
            "Restoring: G_synthesis/32x32/Conv0_up/noise_strength\n",
            "Restoring: G_synthesis/32x32/Conv0_up/bias\n",
            "Restoring: G_synthesis/32x32/Conv1/weight\n",
            "Restoring: G_synthesis/32x32/Conv1/mod_weight\n",
            "Restoring: G_synthesis/32x32/Conv1/mod_bias\n",
            "Restoring: G_synthesis/32x32/Conv1/noise_strength\n",
            "Restoring: G_synthesis/32x32/Conv1/bias\n",
            "Restoring: G_synthesis/32x32/ToRGB/weight\n",
            "Restoring: G_synthesis/32x32/ToRGB/mod_weight\n",
            "Restoring: G_synthesis/32x32/ToRGB/mod_bias\n",
            "Restoring: G_synthesis/32x32/ToRGB/bias\n",
            "Restoring: G_synthesis/64x64/Conv0_up/weight\n",
            "Restoring: G_synthesis/64x64/Conv0_up/mod_weight\n",
            "Restoring: G_synthesis/64x64/Conv0_up/mod_bias\n",
            "Restoring: G_synthesis/64x64/Conv0_up/noise_strength\n",
            "Restoring: G_synthesis/64x64/Conv0_up/bias\n",
            "Restoring: G_synthesis/64x64/Conv1/weight\n",
            "Restoring: G_synthesis/64x64/Conv1/mod_weight\n",
            "Restoring: G_synthesis/64x64/Conv1/mod_bias\n",
            "Restoring: G_synthesis/64x64/Conv1/noise_strength\n",
            "Restoring: G_synthesis/64x64/Conv1/bias\n",
            "Restoring: G_synthesis/64x64/ToRGB/weight\n",
            "Restoring: G_synthesis/64x64/ToRGB/mod_weight\n",
            "Restoring: G_synthesis/64x64/ToRGB/mod_bias\n",
            "Restoring: G_synthesis/64x64/ToRGB/bias\n",
            "Restoring: G_synthesis/128x128/Conv0_up/weight\n",
            "Restoring: G_synthesis/128x128/Conv0_up/mod_weight\n",
            "Restoring: G_synthesis/128x128/Conv0_up/mod_bias\n",
            "Restoring: G_synthesis/128x128/Conv0_up/noise_strength\n",
            "Restoring: G_synthesis/128x128/Conv0_up/bias\n",
            "Restoring: G_synthesis/128x128/Conv1/weight\n",
            "Restoring: G_synthesis/128x128/Conv1/mod_weight\n",
            "Restoring: G_synthesis/128x128/Conv1/mod_bias\n",
            "Restoring: G_synthesis/128x128/Conv1/noise_strength\n",
            "Restoring: G_synthesis/128x128/Conv1/bias\n",
            "Restoring: G_synthesis/128x128/ToRGB/weight\n",
            "Restoring: G_synthesis/128x128/ToRGB/mod_weight\n",
            "Restoring: G_synthesis/128x128/ToRGB/mod_bias\n",
            "Restoring: G_synthesis/128x128/ToRGB/bias\n",
            "Restoring: G_synthesis/256x256/Conv0_up/weight\n",
            "Restoring: G_synthesis/256x256/Conv0_up/mod_weight\n",
            "Restoring: G_synthesis/256x256/Conv0_up/mod_bias\n",
            "Restoring: G_synthesis/256x256/Conv0_up/noise_strength\n",
            "Restoring: G_synthesis/256x256/Conv0_up/bias\n",
            "Restoring: G_synthesis/256x256/Conv1/weight\n",
            "Restoring: G_synthesis/256x256/Conv1/mod_weight\n",
            "Restoring: G_synthesis/256x256/Conv1/mod_bias\n",
            "Restoring: G_synthesis/256x256/Conv1/noise_strength\n",
            "Restoring: G_synthesis/256x256/Conv1/bias\n",
            "Restoring: G_synthesis/256x256/ToRGB/weight\n",
            "Restoring: G_synthesis/256x256/ToRGB/mod_weight\n",
            "Restoring: G_synthesis/256x256/ToRGB/mod_bias\n",
            "Restoring: G_synthesis/256x256/ToRGB/bias\n",
            "Restoring: G_mapping/Dense0/weight\n",
            "Restoring: G_mapping/Dense0/bias\n",
            "Restoring: G_mapping/Dense1/weight\n",
            "Restoring: G_mapping/Dense1/bias\n",
            "Restoring: G_mapping/Dense2/weight\n",
            "Restoring: G_mapping/Dense2/bias\n",
            "Restoring: G_mapping/Dense3/weight\n",
            "Restoring: G_mapping/Dense3/bias\n",
            "Restoring: G_mapping/Dense4/weight\n",
            "Restoring: G_mapping/Dense4/bias\n",
            "Restoring: G_mapping/Dense5/weight\n",
            "Restoring: G_mapping/Dense5/bias\n",
            "Restoring: G_mapping/Dense6/weight\n",
            "Restoring: G_mapping/Dense6/bias\n",
            "Restoring: G_mapping/Dense7/weight\n",
            "Restoring: G_mapping/Dense7/bias\n",
            "Not restoring (not present):     256x256/FromRGB/weight\n",
            "Not restoring (not present):     256x256/FromRGB/bias\n",
            "Restoring: 256x256/Conv0/weight\n",
            "Restoring: 256x256/Conv0/bias\n",
            "Restoring: 256x256/Conv1_down/weight\n",
            "Restoring: 256x256/Conv1_down/bias\n",
            "Restoring: 256x256/Skip/weight\n",
            "Restoring: 128x128/Conv0/weight\n",
            "Restoring: 128x128/Conv0/bias\n",
            "Restoring: 128x128/Conv1_down/weight\n",
            "Restoring: 128x128/Conv1_down/bias\n",
            "Restoring: 128x128/Skip/weight\n",
            "Restoring: 64x64/Conv0/weight\n",
            "Restoring: 64x64/Conv0/bias\n",
            "Restoring: 64x64/Conv1_down/weight\n",
            "Restoring: 64x64/Conv1_down/bias\n",
            "Restoring: 64x64/Skip/weight\n",
            "Restoring: 32x32/Conv0/weight\n",
            "Restoring: 32x32/Conv0/bias\n",
            "Restoring: 32x32/Conv1_down/weight\n",
            "Restoring: 32x32/Conv1_down/bias\n",
            "Restoring: 32x32/Skip/weight\n",
            "Restoring: 16x16/Conv0/weight\n",
            "Restoring: 16x16/Conv0/bias\n",
            "Restoring: 16x16/Conv1_down/weight\n",
            "Restoring: 16x16/Conv1_down/bias\n",
            "Restoring: 16x16/Skip/weight\n",
            "Restoring: 8x8/Conv0/weight\n",
            "Restoring: 8x8/Conv0/bias\n",
            "Restoring: 8x8/Conv1_down/weight\n",
            "Restoring: 8x8/Conv1_down/bias\n",
            "Restoring: 8x8/Skip/weight\n",
            "Restoring: 4x4/Conv/weight\n",
            "Restoring: 4x4/Conv/bias\n",
            "Restoring: 4x4/Dense0/weight\n",
            "Restoring: 4x4/Dense0/bias\n",
            "Restoring: Output/weight\n",
            "Restoring: Output/bias\n",
            "Restoring: G_synthesis/4x4/Const/const\n",
            "Restoring: G_synthesis/4x4/Conv/weight\n",
            "Restoring: G_synthesis/4x4/Conv/mod_weight\n",
            "Restoring: G_synthesis/4x4/Conv/mod_bias\n",
            "Restoring: G_synthesis/4x4/Conv/noise_strength\n",
            "Restoring: G_synthesis/4x4/Conv/bias\n",
            "Restoring: G_synthesis/4x4/ToRGB/weight\n",
            "Restoring: G_synthesis/4x4/ToRGB/mod_weight\n",
            "Restoring: G_synthesis/4x4/ToRGB/mod_bias\n",
            "Restoring: G_synthesis/4x4/ToRGB/bias\n",
            "Restoring: G_synthesis/8x8/Conv0_up/weight\n",
            "Restoring: G_synthesis/8x8/Conv0_up/mod_weight\n",
            "Restoring: G_synthesis/8x8/Conv0_up/mod_bias\n",
            "Restoring: G_synthesis/8x8/Conv0_up/noise_strength\n",
            "Restoring: G_synthesis/8x8/Conv0_up/bias\n",
            "Restoring: G_synthesis/8x8/Conv1/weight\n",
            "Restoring: G_synthesis/8x8/Conv1/mod_weight\n",
            "Restoring: G_synthesis/8x8/Conv1/mod_bias\n",
            "Restoring: G_synthesis/8x8/Conv1/noise_strength\n",
            "Restoring: G_synthesis/8x8/Conv1/bias\n",
            "Restoring: G_synthesis/8x8/ToRGB/weight\n",
            "Restoring: G_synthesis/8x8/ToRGB/mod_weight\n",
            "Restoring: G_synthesis/8x8/ToRGB/mod_bias\n",
            "Restoring: G_synthesis/8x8/ToRGB/bias\n",
            "Restoring: G_synthesis/16x16/Conv0_up/weight\n",
            "Restoring: G_synthesis/16x16/Conv0_up/mod_weight\n",
            "Restoring: G_synthesis/16x16/Conv0_up/mod_bias\n",
            "Restoring: G_synthesis/16x16/Conv0_up/noise_strength\n",
            "Restoring: G_synthesis/16x16/Conv0_up/bias\n",
            "Restoring: G_synthesis/16x16/Conv1/weight\n",
            "Restoring: G_synthesis/16x16/Conv1/mod_weight\n",
            "Restoring: G_synthesis/16x16/Conv1/mod_bias\n",
            "Restoring: G_synthesis/16x16/Conv1/noise_strength\n",
            "Restoring: G_synthesis/16x16/Conv1/bias\n",
            "Restoring: G_synthesis/16x16/ToRGB/weight\n",
            "Restoring: G_synthesis/16x16/ToRGB/mod_weight\n",
            "Restoring: G_synthesis/16x16/ToRGB/mod_bias\n",
            "Restoring: G_synthesis/16x16/ToRGB/bias\n",
            "Restoring: G_synthesis/32x32/Conv0_up/weight\n",
            "Restoring: G_synthesis/32x32/Conv0_up/mod_weight\n",
            "Restoring: G_synthesis/32x32/Conv0_up/mod_bias\n",
            "Restoring: G_synthesis/32x32/Conv0_up/noise_strength\n",
            "Restoring: G_synthesis/32x32/Conv0_up/bias\n",
            "Restoring: G_synthesis/32x32/Conv1/weight\n",
            "Restoring: G_synthesis/32x32/Conv1/mod_weight\n",
            "Restoring: G_synthesis/32x32/Conv1/mod_bias\n",
            "Restoring: G_synthesis/32x32/Conv1/noise_strength\n",
            "Restoring: G_synthesis/32x32/Conv1/bias\n",
            "Restoring: G_synthesis/32x32/ToRGB/weight\n",
            "Restoring: G_synthesis/32x32/ToRGB/mod_weight\n",
            "Restoring: G_synthesis/32x32/ToRGB/mod_bias\n",
            "Restoring: G_synthesis/32x32/ToRGB/bias\n",
            "Restoring: G_synthesis/64x64/Conv0_up/weight\n",
            "Restoring: G_synthesis/64x64/Conv0_up/mod_weight\n",
            "Restoring: G_synthesis/64x64/Conv0_up/mod_bias\n",
            "Restoring: G_synthesis/64x64/Conv0_up/noise_strength\n",
            "Restoring: G_synthesis/64x64/Conv0_up/bias\n",
            "Restoring: G_synthesis/64x64/Conv1/weight\n",
            "Restoring: G_synthesis/64x64/Conv1/mod_weight\n",
            "Restoring: G_synthesis/64x64/Conv1/mod_bias\n",
            "Restoring: G_synthesis/64x64/Conv1/noise_strength\n",
            "Restoring: G_synthesis/64x64/Conv1/bias\n",
            "Restoring: G_synthesis/64x64/ToRGB/weight\n",
            "Restoring: G_synthesis/64x64/ToRGB/mod_weight\n",
            "Restoring: G_synthesis/64x64/ToRGB/mod_bias\n",
            "Restoring: G_synthesis/64x64/ToRGB/bias\n",
            "Restoring: G_synthesis/128x128/Conv0_up/weight\n",
            "Restoring: G_synthesis/128x128/Conv0_up/mod_weight\n",
            "Restoring: G_synthesis/128x128/Conv0_up/mod_bias\n",
            "Restoring: G_synthesis/128x128/Conv0_up/noise_strength\n",
            "Restoring: G_synthesis/128x128/Conv0_up/bias\n",
            "Restoring: G_synthesis/128x128/Conv1/weight\n",
            "Restoring: G_synthesis/128x128/Conv1/mod_weight\n",
            "Restoring: G_synthesis/128x128/Conv1/mod_bias\n",
            "Restoring: G_synthesis/128x128/Conv1/noise_strength\n",
            "Restoring: G_synthesis/128x128/Conv1/bias\n",
            "Restoring: G_synthesis/128x128/ToRGB/weight\n",
            "Restoring: G_synthesis/128x128/ToRGB/mod_weight\n",
            "Restoring: G_synthesis/128x128/ToRGB/mod_bias\n",
            "Restoring: G_synthesis/128x128/ToRGB/bias\n",
            "Restoring: G_synthesis/256x256/Conv0_up/weight\n",
            "Restoring: G_synthesis/256x256/Conv0_up/mod_weight\n",
            "Restoring: G_synthesis/256x256/Conv0_up/mod_bias\n",
            "Restoring: G_synthesis/256x256/Conv0_up/noise_strength\n",
            "Restoring: G_synthesis/256x256/Conv0_up/bias\n",
            "Restoring: G_synthesis/256x256/Conv1/weight\n",
            "Restoring: G_synthesis/256x256/Conv1/mod_weight\n",
            "Restoring: G_synthesis/256x256/Conv1/mod_bias\n",
            "Restoring: G_synthesis/256x256/Conv1/noise_strength\n",
            "Restoring: G_synthesis/256x256/Conv1/bias\n",
            "Restoring: G_synthesis/256x256/ToRGB/weight\n",
            "Restoring: G_synthesis/256x256/ToRGB/mod_weight\n",
            "Restoring: G_synthesis/256x256/ToRGB/mod_bias\n",
            "Restoring: G_synthesis/256x256/ToRGB/bias\n",
            "Restoring: G_mapping/Dense0/weight\n",
            "Restoring: G_mapping/Dense0/bias\n",
            "Restoring: G_mapping/Dense1/weight\n",
            "Restoring: G_mapping/Dense1/bias\n",
            "Restoring: G_mapping/Dense2/weight\n",
            "Restoring: G_mapping/Dense2/bias\n",
            "Restoring: G_mapping/Dense3/weight\n",
            "Restoring: G_mapping/Dense3/bias\n",
            "Restoring: G_mapping/Dense4/weight\n",
            "Restoring: G_mapping/Dense4/bias\n",
            "Restoring: G_mapping/Dense5/weight\n",
            "Restoring: G_mapping/Dense5/bias\n",
            "Restoring: G_mapping/Dense6/weight\n",
            "Restoring: G_mapping/Dense6/bias\n",
            "Restoring: G_mapping/Dense7/weight\n",
            "Restoring: G_mapping/Dense7/bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPecp8o9CKNJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6834a63-6ae6-446a-df76-905fbd2aaab6"
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0W9Tyn2NBjG"
      },
      "source": [
        "# Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWMPNER11Z_A"
      },
      "source": [
        "import os\n",
        "from fastai.vision import verify_images\n",
        "verify_images(local_path, delete=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBbkV2Fq_CUy"
      },
      "source": [
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from os import mkdir\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnu0I2dVke1o"
      },
      "source": [
        "for p in [\"datasets/\", 'datasets/custom']:\n",
        "  try:\n",
        "    os.mkdir(p)\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4nNOUx6LbU8"
      },
      "source": [
        "Creates a TF records file which stylegan2 ada needs to train successfully!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrd-UJH5_pXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae127a73-8ef7-4371-b93f-a49af5bfad0c"
      },
      "source": [
        "%cd /content/stylegan2-ada/\n",
        "!python dataset_tool.py create_from_images /content/datasets/custom/ /content/my_data/train_final/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylegan2-ada\n",
            "Loading images from \"/content/my_data/train_final/\"\n",
            "Creating dataset \"/content/datasets/custom/\"\n",
            "dataset_tool.py:96: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
            "  'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n",
            "Added 29 images.\n",
            "Traceback (most recent call last):\n",
            "  File \"dataset_tool.py\", line 993, in <module>\n",
            "    execute_cmdline(sys.argv)\n",
            "  File \"dataset_tool.py\", line 988, in execute_cmdline\n",
            "    func(**vars(args))\n",
            "  File \"dataset_tool.py\", line 677, in create_from_images\n",
            "    tfr.add_image(img)\n",
            "  File \"dataset_tool.py\", line 88, in add_image\n",
            "    assert img.shape == self.shape\n",
            "AssertionError\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdnBhgrwblt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85fd72f2-3185-4d32-ce2a-6d0ca52ba652"
      },
      "source": [
        "%cd /content/stylegan2-ada/training"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylegan2-ada/training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhwL9nVrLI-2"
      },
      "source": [
        "#Training loop changes\n",
        "\n",
        "Some minor changes to the training loop. Mainly creating a checkpoint every 10,000 images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F8bZxFECqpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c25313-05ac-4660-ad09-afbd4fa89c2c"
      },
      "source": [
        "%%writefile training_loop.py\n",
        "﻿# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.\n",
        "#\n",
        "# NVIDIA CORPORATION and its licensors retain all intellectual property\n",
        "# and proprietary rights in and to this software, related documentation\n",
        "# and any modifications thereto.  Any use, reproduction, disclosure or\n",
        "# distribution of this software and related documentation without an express\n",
        "# license agreement from NVIDIA CORPORATION is strictly prohibited.\n",
        "\n",
        "\"\"\"Main training loop.\"\"\"\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import time\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "from dnnlib.tflib.autosummary import autosummary\n",
        "\n",
        "from training import dataset\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Select size and contents of the image snapshot grids that are exported\n",
        "# periodically during training.\n",
        "\n",
        "def setup_snapshot_image_grid(training_set):\n",
        "    gw = np.clip(7680 // training_set.shape[2], 7, 32)\n",
        "    gh = np.clip(4320 // training_set.shape[1], 4, 32)\n",
        "\n",
        "    # Unconditional.\n",
        "    if training_set.label_size == 0:\n",
        "        reals, labels = training_set.get_minibatch_np(gw * gh)\n",
        "        return (gw, gh), reals, labels\n",
        "\n",
        "    # Row per class.\n",
        "    cw, ch = (gw, 1)\n",
        "    nw = (gw - 1) // cw + 1\n",
        "    nh = (gh - 1) // ch + 1\n",
        "\n",
        "    # Collect images.\n",
        "    blocks = [[] for _i in range(nw * nh)]\n",
        "    for _iter in range(1000000):\n",
        "        real, label = training_set.get_minibatch_np(1)\n",
        "        idx = np.argmax(label[0])\n",
        "        while idx < len(blocks) and len(blocks[idx]) >= cw * ch:\n",
        "            idx += training_set.label_size\n",
        "        if idx < len(blocks):\n",
        "            blocks[idx].append((real, label))\n",
        "            if all(len(block) >= cw * ch for block in blocks):\n",
        "                break\n",
        "\n",
        "    # Layout grid.\n",
        "    reals = np.zeros([gw * gh] + training_set.shape, dtype=training_set.dtype)\n",
        "    labels = np.zeros([gw * gh, training_set.label_size], dtype=training_set.label_dtype)\n",
        "    for i, block in enumerate(blocks):\n",
        "        for j, (real, label) in enumerate(block):\n",
        "            x = (i %  nw) * cw + j %  cw\n",
        "            y = (i // nw) * ch + j // cw\n",
        "            if x < gw and y < gh:\n",
        "                reals[x + y * gw] = real[0]\n",
        "                labels[x + y * gw] = label[0]\n",
        "    return (gw, gh), reals, labels\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def save_image_grid(images, filename, drange, grid_size):\n",
        "    lo, hi = drange\n",
        "    gw, gh = grid_size\n",
        "    images = np.asarray(images, dtype=np.float32)\n",
        "    images = (images - lo) * (255 / (hi - lo))\n",
        "    images = np.rint(images).clip(0, 255).astype(np.uint8)\n",
        "    _N, C, H, W = images.shape\n",
        "    images = images.reshape(gh, gw, C, H, W)\n",
        "    images = images.transpose(0, 3, 1, 4, 2)\n",
        "    images = images.reshape(gh * H, gw * W, C)\n",
        "    PIL.Image.fromarray(images, {3: 'RGB', 1: 'L'}[C]).save(filename)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Main training script.\n",
        "\n",
        "def training_loop(\n",
        "    run_dir                 = '.',      # Output directory.\n",
        "    G_args                  = {},       # Options for generator network.\n",
        "    D_args                  = {},       # Options for discriminator network.\n",
        "    G_opt_args              = {},       # Options for generator optimizer.\n",
        "    D_opt_args              = {},       # Options for discriminator optimizer.\n",
        "    loss_args               = {},       # Options for loss function.\n",
        "    train_dataset_args      = {},       # Options for dataset to train with.\n",
        "    metric_dataset_args     = {},       # Options for dataset to evaluate metrics against.\n",
        "    augment_args            = {},       # Options for adaptive augmentations.\n",
        "    metric_arg_list         = [],       # Metrics to evaluate during training.\n",
        "    num_gpus                = 1,        # Number of GPUs to use.\n",
        "    minibatch_size          = 32,       # Global minibatch size.\n",
        "    minibatch_gpu           = 4,        # Number of samples processed at a time by one GPU.\n",
        "    G_smoothing_kimg        = 10,       # Half-life of the exponential moving average (EMA) of generator weights.\n",
        "    G_smoothing_rampup      = None,     # EMA ramp-up coefficient.\n",
        "    minibatch_repeats       = 4,        # Number of minibatches to run in the inner loop.\n",
        "    lazy_regularization     = True,     # Perform regularization as a separate training step?\n",
        "    G_reg_interval          = 4,        # How often the perform regularization for G? Ignored if lazy_regularization=False.\n",
        "    D_reg_interval          = 16,       # How often the perform regularization for D? Ignored if lazy_regularization=False.\n",
        "    total_kimg              = 25000,    # Total length of the training, measured in thousands of real images.\n",
        "    kimg_per_tick           = 10,        # Progress snapshot interval.\n",
        "    image_snapshot_ticks    = 1,       # How often to save image snapshots? None = only save 'reals.png' and 'fakes-init.png'.\n",
        "    network_snapshot_ticks  = 1,       # How often to save network snapshots? None = only save 'networks-final.pkl'.\n",
        "    resume_pkl              = None,     # Network pickle to resume training from, None = train from scratch.\n",
        "    resume_kimg             = 15000,      # Assumed training progress at the beginning. Affects reporting and training schedule.\n",
        "    resume_time             = 0.0,      # Assumed wallclock time at the beginning. Affects reporting.\n",
        "    abort_fn                = None,     # Callback function for determining whether to abort training.\n",
        "    progress_fn             = None,     # Callback function for updating training progress.\n",
        "):\n",
        "    assert minibatch_size % (num_gpus * minibatch_gpu) == 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    print('Loading training set...')\n",
        "    training_set = dataset.load_dataset(**train_dataset_args)\n",
        "    print('Image shape:', np.int32(training_set.shape).tolist())\n",
        "    print('Label shape:', [training_set.label_size])\n",
        "    print()\n",
        "\n",
        "    print('Constructing networks...')\n",
        "    with tf.device('/gpu:0'):\n",
        "        G = tflib.Network('G', num_channels=training_set.shape[0], resolution=training_set.shape[1], label_size=training_set.label_size, **G_args)\n",
        "        D = tflib.Network('D', num_channels=training_set.shape[0], resolution=training_set.shape[1], label_size=training_set.label_size, **D_args)\n",
        "        Gs = G.clone('Gs')\n",
        "        if resume_pkl is not None:\n",
        "            print(f'Resuming from \"{resume_pkl}\"')\n",
        "            with dnnlib.util.open_url(resume_pkl) as f:\n",
        "                rG, rD, rGs = pickle.load(f)\n",
        "            G.copy_vars_from(rG)\n",
        "            D.copy_vars_from(rD)\n",
        "            Gs.copy_vars_from(rGs)\n",
        "    G.print_layers()\n",
        "    D.print_layers()\n",
        "\n",
        "    print('Exporting sample images...')\n",
        "    grid_size, grid_reals, grid_labels = setup_snapshot_image_grid(training_set)\n",
        "    save_image_grid(grid_reals, os.path.join(run_dir, 'reals.png'), drange=[0,255], grid_size=grid_size)\n",
        "    grid_latents = np.random.randn(np.prod(grid_size), *G.input_shape[1:])\n",
        "    grid_fakes = Gs.run(grid_latents, grid_labels, is_validation=True, minibatch_size=minibatch_gpu)\n",
        "    save_image_grid(grid_fakes, os.path.join(run_dir, 'fakes_init.png'), drange=[-1,1], grid_size=grid_size)\n",
        "\n",
        "    print(f'Replicating networks across {num_gpus} GPUs...')\n",
        "    G_gpus = [G]\n",
        "    D_gpus = [D]\n",
        "    for gpu in range(1, num_gpus):\n",
        "        with tf.device(f'/gpu:{gpu}'):\n",
        "            G_gpus.append(G.clone(f'{G.name}_gpu{gpu}'))\n",
        "            D_gpus.append(D.clone(f'{D.name}_gpu{gpu}'))\n",
        "\n",
        "    print('Initializing augmentations...')\n",
        "    aug = None\n",
        "    if augment_args.get('class_name', None) is not None:\n",
        "        aug = dnnlib.util.construct_class_by_name(**augment_args)\n",
        "        aug.init_validation_set(D_gpus=D_gpus, training_set=training_set)\n",
        "\n",
        "    print('Setting up optimizers...')\n",
        "    G_opt_args = dict(G_opt_args)\n",
        "    D_opt_args = dict(D_opt_args)\n",
        "    for args, reg_interval in [(G_opt_args, G_reg_interval), (D_opt_args, D_reg_interval)]:\n",
        "        args['minibatch_multiplier'] = minibatch_size // num_gpus // minibatch_gpu\n",
        "        if lazy_regularization:\n",
        "            mb_ratio = reg_interval / (reg_interval + 1)\n",
        "            args['learning_rate'] *= mb_ratio\n",
        "            if 'beta1' in args: args['beta1'] **= mb_ratio\n",
        "            if 'beta2' in args: args['beta2'] **= mb_ratio\n",
        "    G_opt = tflib.Optimizer(name='TrainG', **G_opt_args)\n",
        "    D_opt = tflib.Optimizer(name='TrainD', **D_opt_args)\n",
        "    G_reg_opt = tflib.Optimizer(name='RegG', share=G_opt, **G_opt_args)\n",
        "    D_reg_opt = tflib.Optimizer(name='RegD', share=D_opt, **D_opt_args)\n",
        "\n",
        "    print('Constructing training graph...')\n",
        "    data_fetch_ops = []\n",
        "    training_set.configure(minibatch_gpu)\n",
        "    for gpu, (G_gpu, D_gpu) in enumerate(zip(G_gpus, D_gpus)):\n",
        "        with tf.name_scope(f'Train_gpu{gpu}'), tf.device(f'/gpu:{gpu}'):\n",
        "\n",
        "            # Fetch training data via temporary variables.\n",
        "            with tf.name_scope('DataFetch'):\n",
        "                real_images_var = tf.Variable(name='images', trainable=False, initial_value=tf.zeros([minibatch_gpu] + training_set.shape))\n",
        "                real_labels_var = tf.Variable(name='labels', trainable=False, initial_value=tf.zeros([minibatch_gpu, training_set.label_size]))\n",
        "                real_images_write, real_labels_write = training_set.get_minibatch_tf()\n",
        "                real_images_write = tflib.convert_images_from_uint8(real_images_write)\n",
        "                data_fetch_ops += [tf.assign(real_images_var, real_images_write)]\n",
        "                data_fetch_ops += [tf.assign(real_labels_var, real_labels_write)]\n",
        "\n",
        "            # Evaluate loss function and register gradients.\n",
        "            fake_labels = training_set.get_random_labels_tf(minibatch_gpu)\n",
        "            terms = dnnlib.util.call_func_by_name(G=G_gpu, D=D_gpu, aug=aug, fake_labels=fake_labels, real_images=real_images_var, real_labels=real_labels_var, **loss_args)\n",
        "            if lazy_regularization:\n",
        "                if terms.G_reg is not None: G_reg_opt.register_gradients(tf.reduce_mean(terms.G_reg * G_reg_interval), G_gpu.trainables)\n",
        "                if terms.D_reg is not None: D_reg_opt.register_gradients(tf.reduce_mean(terms.D_reg * D_reg_interval), D_gpu.trainables)\n",
        "            else:\n",
        "                if terms.G_reg is not None: terms.G_loss += terms.G_reg\n",
        "                if terms.D_reg is not None: terms.D_loss += terms.D_reg\n",
        "            G_opt.register_gradients(tf.reduce_mean(terms.G_loss), G_gpu.trainables)\n",
        "            D_opt.register_gradients(tf.reduce_mean(terms.D_loss), D_gpu.trainables)\n",
        "\n",
        "    print('Finalizing training ops...')\n",
        "    data_fetch_op = tf.group(*data_fetch_ops)\n",
        "    G_train_op = G_opt.apply_updates()\n",
        "    D_train_op = D_opt.apply_updates()\n",
        "    G_reg_op = G_reg_opt.apply_updates(allow_no_op=True)\n",
        "    D_reg_op = D_reg_opt.apply_updates(allow_no_op=True)\n",
        "    Gs_beta_in = tf.placeholder(tf.float32, name='Gs_beta_in', shape=[])\n",
        "    Gs_update_op = Gs.setup_as_moving_average_of(G, beta=Gs_beta_in)\n",
        "    tflib.init_uninitialized_vars()\n",
        "    with tf.device('/gpu:0'):\n",
        "        peak_gpu_mem_op = tf.contrib.memory_stats.MaxBytesInUse()\n",
        "\n",
        "    print('Initializing metrics...')\n",
        "    summary_log = tf.summary.FileWriter(run_dir)\n",
        "    metrics = []\n",
        "    for args in metric_arg_list:\n",
        "        metric = dnnlib.util.construct_class_by_name(**args)\n",
        "        metric.configure(dataset_args=metric_dataset_args, run_dir=run_dir)\n",
        "        metrics.append(metric)\n",
        "\n",
        "    print(f'Training for {total_kimg} kimg...')\n",
        "    print()\n",
        "    if progress_fn is not None:\n",
        "        progress_fn(0, total_kimg)\n",
        "    tick_start_time = time.time()\n",
        "    maintenance_time = tick_start_time - start_time\n",
        "    cur_nimg = 0\n",
        "    cur_tick = -1\n",
        "    tick_start_nimg = cur_nimg\n",
        "    running_mb_counter = 0\n",
        "\n",
        "    done = False\n",
        "    while not done:\n",
        "\n",
        "        # Compute EMA decay parameter.\n",
        "        Gs_nimg = G_smoothing_kimg * 1000.0\n",
        "        if G_smoothing_rampup is not None:\n",
        "            Gs_nimg = min(Gs_nimg, cur_nimg * G_smoothing_rampup)\n",
        "        Gs_beta = 0.5 ** (minibatch_size / max(Gs_nimg, 1e-8))\n",
        "\n",
        "        # Run training ops.\n",
        "        for _repeat_idx in range(minibatch_repeats):\n",
        "            rounds = range(0, minibatch_size, minibatch_gpu * num_gpus)\n",
        "            run_G_reg = (lazy_regularization and running_mb_counter % G_reg_interval == 0)\n",
        "            run_D_reg = (lazy_regularization and running_mb_counter % D_reg_interval == 0)\n",
        "            cur_nimg += minibatch_size\n",
        "            running_mb_counter += 1\n",
        "\n",
        "            # Fast path without gradient accumulation.\n",
        "            if len(rounds) == 1:\n",
        "                tflib.run([G_train_op, data_fetch_op])\n",
        "                if run_G_reg:\n",
        "                    tflib.run(G_reg_op)\n",
        "                tflib.run([D_train_op, Gs_update_op], {Gs_beta_in: Gs_beta})\n",
        "                if run_D_reg:\n",
        "                    tflib.run(D_reg_op)\n",
        "\n",
        "            # Slow path with gradient accumulation.\n",
        "            else:\n",
        "                for _round in rounds:\n",
        "                    tflib.run(G_train_op)\n",
        "                    if run_G_reg:\n",
        "                        tflib.run(G_reg_op)\n",
        "                tflib.run(Gs_update_op, {Gs_beta_in: Gs_beta})\n",
        "                for _round in rounds:\n",
        "                    tflib.run(data_fetch_op)\n",
        "                    tflib.run(D_train_op)\n",
        "                    if run_D_reg:\n",
        "                        tflib.run(D_reg_op)\n",
        "\n",
        "            # Run validation.\n",
        "            if aug is not None:\n",
        "                aug.run_validation(minibatch_size=minibatch_size)\n",
        "\n",
        "        # Tune augmentation parameters.\n",
        "        if aug is not None:\n",
        "            aug.tune(minibatch_size * minibatch_repeats)\n",
        "\n",
        "        # Perform maintenance tasks once per tick.\n",
        "        done = (cur_nimg >= total_kimg * 1000) or (abort_fn is not None and abort_fn())\n",
        "        if done or cur_tick < 0 or cur_nimg >= tick_start_nimg + kimg_per_tick * 1000:\n",
        "            cur_tick += 1\n",
        "            tick_kimg = (cur_nimg - tick_start_nimg) / 1000.0\n",
        "            tick_start_nimg = cur_nimg\n",
        "            tick_end_time = time.time()\n",
        "            total_time = tick_end_time - start_time\n",
        "            tick_time = tick_end_time - tick_start_time\n",
        "\n",
        "            # Report progress.\n",
        "            print(' '.join([\n",
        "                f\"tick {autosummary('Progress/tick', cur_tick):<5d}\",\n",
        "                f\"kimg {autosummary('Progress/kimg', cur_nimg / 1000.0):<8.1f}\",\n",
        "                f\"time {dnnlib.util.format_time(autosummary('Timing/total_sec', total_time)):<12s}\",\n",
        "                f\"sec/tick {autosummary('Timing/sec_per_tick', tick_time):<7.1f}\",\n",
        "                f\"sec/kimg {autosummary('Timing/sec_per_kimg', tick_time / tick_kimg):<7.2f}\",\n",
        "                f\"maintenance {autosummary('Timing/maintenance_sec', maintenance_time):<6.1f}\",\n",
        "                f\"gpumem {autosummary('Resources/peak_gpu_mem_gb', peak_gpu_mem_op.eval() / 2**30):<5.1f}\",\n",
        "                f\"augment {autosummary('Progress/augment', aug.strength if aug is not None else 0):.3f}\",\n",
        "            ]))\n",
        "            autosummary('Timing/total_hours', total_time / (60.0 * 60.0))\n",
        "            autosummary('Timing/total_days', total_time / (24.0 * 60.0 * 60.0))\n",
        "            if progress_fn is not None:\n",
        "                progress_fn(cur_nimg // 1000, total_kimg)\n",
        "\n",
        "            # Save snapshots.\n",
        "            if image_snapshot_ticks is not None and (done or cur_tick % image_snapshot_ticks == 0):\n",
        "                grid_fakes = Gs.run(grid_latents, grid_labels, is_validation=True, minibatch_size=minibatch_gpu)\n",
        "                save_image_grid(grid_fakes, os.path.join(run_dir, f'fakes{cur_nimg // 1000:06d}.png'), drange=[-1,1], grid_size=grid_size)\n",
        "\n",
        "            if network_snapshot_ticks is not None and (done or cur_tick % network_snapshot_ticks == 0):\n",
        "                pkl = os.path.join(run_dir, f'network-snapshot-{cur_nimg // 1000:06d}.pkl')\n",
        "                with open(pkl, 'wb') as f:\n",
        "                    pickle.dump((G, D, Gs), f)\n",
        "                if len(metrics):\n",
        "                    print('Evaluating metrics...')\n",
        "                    for metric in metrics:\n",
        "                        metric.run(pkl, num_gpus=num_gpus)\n",
        "\n",
        "            # Update summaries.\n",
        "            for metric in metrics:\n",
        "                metric.update_autosummaries()\n",
        "            tflib.autosummary.save_summaries(summary_log, cur_nimg)\n",
        "            tick_start_time = time.time()\n",
        "            maintenance_time = tick_start_time - tick_end_time\n",
        "\n",
        "    print()\n",
        "    print('Exiting...')\n",
        "    summary_log.close()\n",
        "    training_set.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting training_loop.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8qcPk0sPMln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "757b8629-7061-403f-cf48-ddab3f35929e"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylegan2-ada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUES7ATGIWCI"
      },
      "source": [
        "## Start the training of the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPRz35T4QVRu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c119743-1d86-4187-c19f-1f4a91a5c58e"
      },
      "source": [
        "# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.\n",
        "#\n",
        "# NVIDIA CORPORATION and its licensors retain all intellectual property\n",
        "# and proprietary rights in and to this software, related documentation\n",
        "# and any modifications thereto.  Any use, reproduction, disclosure or\n",
        "# distribution of this software and related documentation without an express\n",
        "# license agreement from NVIDIA CORPORATION is strictly prohibited.\n",
        "\n",
        "\"\"\"Train a GAN using the techniques described in the paper\n",
        "\"Training Generative Adversarial Networks with Limited Data\".\"\"\"\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import json\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "\n",
        "from training import training_loop\n",
        "from training import dataset\n",
        "from metrics import metric_defaults\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "class UserError(Exception):\n",
        "    pass\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def setup_training_options():\n",
        "\n",
        "###########################################################################################################################\n",
        "#                                                 EDIT THESE!                                                             #\n",
        "###########################################################################################################################\n",
        "    outdir = '/content/drive/My Drive/Colab Notebooks/styleganada-results/'\n",
        "    gpus = None # Number of GPUs: <int>, default = 1 gpu\n",
        "    snap = 1 # Snapshot interval: <int>, default = 50 ticks\n",
        "    seed = 1000\n",
        "    data = '/content/datasets/custom/'# Training dataset (required): <path>\n",
        "    res = None# Override dataset resolution: <int>, default = highest available\n",
        "    mirror =True# Augment dataset with x-flips: <bool>, default = False\n",
        "    metrics = []# List of metric names: [], ['fid50k_full'] (default), ...\n",
        "    metricdata = None# Metric dataset (optional): <path>\n",
        "    cfg = 'stylegan2'# Base config: 'auto' (default), 'stylegan2', 'paper256', 'paper512', 'paper1024', 'cifar', 'cifarbaseline'\n",
        "    gamma = None# Override R1 gamma: <float>, default = depends on cfg\n",
        "    kimg = 10000# Override training duration: <int>, default = depends on cfg\n",
        "    aug = 'ada' # Augmentation mode: 'ada' (default), 'noaug', 'fixed', 'adarv'\n",
        "    p = None# Specify p for 'fixed' (required): <float>\n",
        "    target = None # Override ADA target for 'ada' and 'adarv': <float>, default = depends on aug\n",
        "    augpipe = 'bgc'# Augmentation pipeline: 'blit', 'geom', 'color', 'filter', 'noise', 'cutout', 'bg', 'bgc' (default), ..., 'bgcfnc'\n",
        "    cmethod = None # Comparison method: 'nocmethod' (default), 'bcr', 'zcr', 'pagan', 'wgangp', 'auxrot', 'spectralnorm', 'shallowmap', 'adropout'\n",
        "    dcap = None # Multiplier for discriminator capacity: <float>, default = 1\n",
        "    augpipe = 'bgc'\n",
        "    resume = '/content/stylegan2-ffhq-config-f.pkl'# Load previous network: 'noresume' (default), 'ffhq256', 'ffhq512', 'ffhq1024', 'celebahq256', 'lsundog256', <file>, <url>\n",
        "    freezed = None # Freeze-D: <int>, default = 0 discriminator layers\n",
        "\n",
        "\n",
        "###########################################################################################################################\n",
        "#                                                 End of Edit Section                                                     #\n",
        "###########################################################################################################################\n",
        "\n",
        "    tflib.init_tf({'rnd.np_random_seed': seed})\n",
        "\n",
        "    # Initialize dicts.\n",
        "    args = dnnlib.EasyDict()\n",
        "    args.G_args = dnnlib.EasyDict(func_name='training.networks.G_main')\n",
        "    args.D_args = dnnlib.EasyDict(func_name='training.networks.D_main')\n",
        "    args.G_opt_args = dnnlib.EasyDict(beta1=0.0, beta2=0.99)\n",
        "    args.D_opt_args = dnnlib.EasyDict(beta1=0.0, beta2=0.99)\n",
        "    args.loss_args = dnnlib.EasyDict(func_name='training.loss.stylegan2')\n",
        "    args.augment_args = dnnlib.EasyDict(class_name='training.augment.AdaptiveAugment')\n",
        "\n",
        "    # ---------------------------\n",
        "    # General options: gpus, snap\n",
        "    # ---------------------------\n",
        "\n",
        "    if gpus is None:\n",
        "        gpus = 1\n",
        "    assert isinstance(gpus, int)\n",
        "    if not (gpus >= 1 and gpus & (gpus - 1) == 0):\n",
        "        raise UserError('--gpus must be a power of two')\n",
        "    args.num_gpus = gpus\n",
        "\n",
        "    if snap is None:\n",
        "        snap = 50\n",
        "    assert isinstance(snap, int)\n",
        "    if snap < 1:\n",
        "        raise UserError('--snap must be at least 1')\n",
        "    args.image_snapshot_ticks = snap\n",
        "    args.network_snapshot_ticks = snap\n",
        "\n",
        "    # -----------------------------------\n",
        "    # Training dataset: data, res, mirror\n",
        "    # -----------------------------------\n",
        "\n",
        "    assert data is not None\n",
        "    assert isinstance(data, str)\n",
        "    data_name = os.path.basename(os.path.abspath(data))\n",
        "    if not os.path.isdir(data) or len(data_name) == 0:\n",
        "        raise UserError('--data must point to a directory containing *.tfrecords')\n",
        "    desc = data_name\n",
        "\n",
        "    with tf.Graph().as_default(), tflib.create_session().as_default(): # pylint: disable=not-context-manager\n",
        "        args.train_dataset_args = dnnlib.EasyDict(path=data, max_label_size='full')\n",
        "        dataset_obj = dataset.load_dataset(**args.train_dataset_args) # try to load the data and see what comes out\n",
        "        args.train_dataset_args.resolution = dataset_obj.shape[-1] # be explicit about resolution\n",
        "        args.train_dataset_args.max_label_size = dataset_obj.label_size # be explicit about label size\n",
        "        validation_set_available = dataset_obj.has_validation_set\n",
        "        dataset_obj.close()\n",
        "        dataset_obj = None\n",
        "\n",
        "    if res is None:\n",
        "        res = args.train_dataset_args.resolution\n",
        "    else:\n",
        "        assert isinstance(res, int)\n",
        "        if not (res >= 4 and res & (res - 1) == 0):\n",
        "            raise UserError('--res must be a power of two and at least 4')\n",
        "        if res > args.train_dataset_args.resolution:\n",
        "            raise UserError(f'--res cannot exceed maximum available resolution in the dataset ({args.train_dataset_args.resolution})')\n",
        "        desc += f'-res{res:d}'\n",
        "    args.train_dataset_args.resolution = res\n",
        "\n",
        "    if mirror is None:\n",
        "        mirror = False\n",
        "    else:\n",
        "        assert isinstance(mirror, bool)\n",
        "        if mirror:\n",
        "            desc += '-mirror'\n",
        "    args.train_dataset_args.mirror_augment = mirror\n",
        "\n",
        "    # ----------------------------\n",
        "    # Metrics: metrics, metricdata\n",
        "    # ----------------------------\n",
        "\n",
        "    if metrics is None:\n",
        "        metrics = ['fid50k_full']\n",
        "    assert isinstance(metrics, list)\n",
        "    assert all(isinstance(metric, str) for metric in metrics)\n",
        "\n",
        "    args.metric_arg_list = []\n",
        "    for metric in metrics:\n",
        "        if metric not in metric_defaults.metric_defaults:\n",
        "            raise UserError('\\n'.join(['--metrics can only contain the following values:', 'none'] + list(metric_defaults.metric_defaults.keys())))\n",
        "        args.metric_arg_list.append(metric_defaults.metric_defaults[metric])\n",
        "\n",
        "    args.metric_dataset_args = dnnlib.EasyDict(args.train_dataset_args)\n",
        "    if metricdata is not None:\n",
        "        assert isinstance(metricdata, str)\n",
        "        if not os.path.isdir(metricdata):\n",
        "            raise UserError('--metricdata must point to a directory containing *.tfrecords')\n",
        "        args.metric_dataset_args.path = metricdata\n",
        "\n",
        "    # -----------------------------\n",
        "    # Base config: cfg, gamma, kimg\n",
        "    # -----------------------------\n",
        "\n",
        "    if cfg is None:\n",
        "        cfg = 'auto'\n",
        "    assert isinstance(cfg, str)\n",
        "    desc += f'-{cfg}'\n",
        "\n",
        "    cfg_specs = {\n",
        "        'auto':          dict(ref_gpus=-1, kimg=25000,  mb=-1, mbstd=-1, fmaps=-1,  lrate=-1,     gamma=-1,   ema=-1,  ramp=0.05, map=2), # populated dynamically based on 'gpus' and 'res'\n",
        "        'stylegan2':     dict(ref_gpus=8,  kimg=25000,  mb=32, mbstd=4,  fmaps=1,   lrate=0.002,  gamma=10,   ema=10,  ramp=None, map=2), # uses mixed-precision, unlike original StyleGAN2\n",
        "        'paper256':      dict(ref_gpus=8,  kimg=25000,  mb=64, mbstd=8,  fmaps=0.5, lrate=0.0025, gamma=1,    ema=20,  ramp=None, map=8),\n",
        "        'paper512':      dict(ref_gpus=8,  kimg=25000,  mb=64, mbstd=8,  fmaps=1,   lrate=0.0025, gamma=0.5,  ema=20,  ramp=None, map=8),\n",
        "        'paper1024':     dict(ref_gpus=8,  kimg=25000,  mb=32, mbstd=4,  fmaps=1,   lrate=0.002,  gamma=2,    ema=10,  ramp=None, map=8),\n",
        "        'cifar':         dict(ref_gpus=2,  kimg=100000, mb=64, mbstd=32, fmaps=0.5, lrate=0.0025, gamma=0.01, ema=500, ramp=0.05, map=2),\n",
        "        'cifarbaseline': dict(ref_gpus=2,  kimg=100000, mb=64, mbstd=32, fmaps=0.5, lrate=0.0025, gamma=0.01, ema=500, ramp=0.05, map=8),\n",
        "    }\n",
        "\n",
        "    assert cfg in cfg_specs\n",
        "    spec = dnnlib.EasyDict(cfg_specs[cfg])\n",
        "    if cfg == 'auto':\n",
        "        desc += f'{gpus:d}'\n",
        "        spec.ref_gpus = gpus\n",
        "        spec.mb = max(min(gpus * min(4096 // res, 32), 64), gpus) # keep gpu memory consumption at bay\n",
        "        spec.mbstd = min(spec.mb // gpus, 4) # other hyperparams behave more predictably if mbstd group size remains fixed\n",
        "        spec.fmaps = 1 if res >= 512 else 0.5\n",
        "        spec.lrate = 0.002 if res >= 1024 else 0.0025\n",
        "        spec.gamma = 0.0002 * (res ** 2) / spec.mb # heuristic formula\n",
        "        spec.ema = spec.mb * 10 / 32\n",
        "\n",
        "    args.total_kimg = spec.kimg\n",
        "    args.minibatch_size = spec.mb\n",
        "    args.minibatch_gpu = spec.mb // spec.ref_gpus\n",
        "    args.D_args.mbstd_group_size = spec.mbstd\n",
        "    args.G_args.fmap_base = args.D_args.fmap_base = int(spec.fmaps * 16384)\n",
        "    args.G_args.fmap_max = args.D_args.fmap_max = 512\n",
        "    args.G_opt_args.learning_rate = args.D_opt_args.learning_rate = spec.lrate\n",
        "    args.loss_args.r1_gamma = spec.gamma\n",
        "    args.G_smoothing_kimg = spec.ema\n",
        "    args.G_smoothing_rampup = spec.ramp\n",
        "    args.G_args.mapping_layers = spec.map\n",
        "    args.G_args.num_fp16_res = args.D_args.num_fp16_res = 4 # enable mixed-precision training\n",
        "    args.G_args.conv_clamp = args.D_args.conv_clamp = 256 # clamp activations to avoid float16 overflow\n",
        "\n",
        "    if cfg == 'cifar':\n",
        "        args.loss_args.pl_weight = 0 # disable path length regularization\n",
        "        args.G_args.style_mixing_prob = None # disable style mixing\n",
        "        args.D_args.architecture = 'orig' # disable residual skip connections\n",
        "\n",
        "    if gamma is not None:\n",
        "        assert isinstance(gamma, float)\n",
        "        if not gamma >= 0:\n",
        "            raise UserError('--gamma must be non-negative')\n",
        "        desc += f'-gamma{gamma:g}'\n",
        "        args.loss_args.r1_gamma = gamma\n",
        "\n",
        "    if kimg is not None:\n",
        "        assert isinstance(kimg, int)\n",
        "        if not kimg >= 1:\n",
        "            raise UserError('--kimg must be at least 1')\n",
        "        desc += f'-kimg{kimg:d}'\n",
        "        args.total_kimg = kimg\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # Discriminator augmentation: aug, p, target, augpipe\n",
        "    # ---------------------------------------------------\n",
        "\n",
        "    if aug is None:\n",
        "        aug = 'ada'\n",
        "    else:\n",
        "        assert isinstance(aug, str)\n",
        "        desc += f'-{aug}'\n",
        "\n",
        "    if aug == 'ada':\n",
        "        args.augment_args.tune_heuristic = 'rt'\n",
        "        args.augment_args.tune_target = 0.6\n",
        "\n",
        "    elif aug == 'noaug':\n",
        "        pass\n",
        "\n",
        "    elif aug == 'fixed':\n",
        "        if p is None:\n",
        "            raise UserError(f'--aug={aug} requires specifying --p')\n",
        "\n",
        "    elif aug == 'adarv':\n",
        "        if not validation_set_available:\n",
        "            raise UserError(f'--aug={aug} requires separate validation set; please see \"python dataset_tool.py pack -h\"')\n",
        "        args.augment_args.tune_heuristic = 'rv'\n",
        "        args.augment_args.tune_target = 0.5\n",
        "\n",
        "    else:\n",
        "        raise UserError(f'--aug={aug} not supported')\n",
        "\n",
        "    if p is not None:\n",
        "        assert isinstance(p, float)\n",
        "        if aug != 'fixed':\n",
        "            raise UserError('--p can only be specified with --aug=fixed')\n",
        "        if not 0 <= p <= 1:\n",
        "            raise UserError('--p must be between 0 and 1')\n",
        "        desc += f'-p{p:g}'\n",
        "        args.augment_args.initial_strength = p\n",
        "\n",
        "    if target is not None:\n",
        "        assert isinstance(target, float)\n",
        "        if aug not in ['ada', 'adarv']:\n",
        "            raise UserError('--target can only be specified with --aug=ada or --aug=adarv')\n",
        "        if not 0 <= target <= 1:\n",
        "            raise UserError('--target must be between 0 and 1')\n",
        "        desc += f'-target{target:g}'\n",
        "        args.augment_args.tune_target = target\n",
        "\n",
        "    assert augpipe is None or isinstance(augpipe, str)\n",
        "    if augpipe is None:\n",
        "        augpipe = 'bgc'\n",
        "    else:\n",
        "        if aug == 'noaug':\n",
        "            raise UserError('--augpipe cannot be specified with --aug=noaug')\n",
        "        desc += f'-{augpipe}'\n",
        "\n",
        "    augpipe_specs = {\n",
        "        'blit':     dict(xflip=1, rotate90=1, xint=1),\n",
        "        'geom':     dict(scale=1, rotate=1, aniso=1, xfrac=1),\n",
        "        'color':    dict(brightness=1, contrast=1, lumaflip=1, hue=1, saturation=1),\n",
        "        'filter':   dict(imgfilter=1),\n",
        "        'noise':    dict(noise=1),\n",
        "        'cutout':   dict(cutout=1),\n",
        "        'bg':       dict(xflip=1, rotate90=1, xint=1, scale=1, rotate=1, aniso=1, xfrac=1),\n",
        "        'bgc':      dict(xflip=1, rotate90=1, xint=1, scale=1, rotate=1, aniso=1, xfrac=1, brightness=1, contrast=1, lumaflip=1, hue=1, saturation=1),\n",
        "        'bgcf':     dict(xflip=1, rotate90=1, xint=1, scale=1, rotate=1, aniso=1, xfrac=1, brightness=1, contrast=1, lumaflip=1, hue=1, saturation=1, imgfilter=1),\n",
        "        'bgcfn':    dict(xflip=1, rotate90=1, xint=1, scale=1, rotate=1, aniso=1, xfrac=1, brightness=1, contrast=1, lumaflip=1, hue=1, saturation=1, imgfilter=1, noise=1),\n",
        "        'bgcfnc':   dict(xflip=1, rotate90=1, xint=1, scale=1, rotate=1, aniso=1, xfrac=1, brightness=1, contrast=1, lumaflip=1, hue=1, saturation=1, imgfilter=1, noise=1, cutout=1),\n",
        "    }\n",
        "\n",
        "    assert augpipe in augpipe_specs\n",
        "    if aug != 'noaug':\n",
        "        args.augment_args.apply_func = 'training.augment.augment_pipeline'\n",
        "        args.augment_args.apply_args = augpipe_specs[augpipe]\n",
        "\n",
        "    # ---------------------------------\n",
        "    # Comparison methods: cmethod, dcap\n",
        "    # ---------------------------------\n",
        "\n",
        "    assert cmethod is None or isinstance(cmethod, str)\n",
        "    if cmethod is None:\n",
        "        cmethod = 'nocmethod'\n",
        "    else:\n",
        "        desc += f'-{cmethod}'\n",
        "\n",
        "    if cmethod == 'nocmethod':\n",
        "        pass\n",
        "\n",
        "    elif cmethod == 'bcr':\n",
        "        args.loss_args.func_name = 'training.loss.cmethods'\n",
        "        args.loss_args.bcr_real_weight = 10\n",
        "        args.loss_args.bcr_fake_weight = 10\n",
        "        args.loss_args.bcr_augment = dnnlib.EasyDict(func_name='training.augment.augment_pipeline', xint=1, xint_max=1/32)\n",
        "\n",
        "    elif cmethod == 'zcr':\n",
        "        args.loss_args.func_name = 'training.loss.cmethods'\n",
        "        args.loss_args.zcr_gen_weight = 0.02\n",
        "        args.loss_args.zcr_dis_weight = 0.2\n",
        "        args.G_args.num_fp16_res = args.D_args.num_fp16_res = 0 # disable mixed-precision training\n",
        "        args.G_args.conv_clamp = args.D_args.conv_clamp = None\n",
        "\n",
        "    elif cmethod == 'pagan':\n",
        "        if aug != 'noaug':\n",
        "            raise UserError(f'--cmethod={cmethod} is not compatible with discriminator augmentation; please specify --aug=noaug')\n",
        "        args.D_args.use_pagan = True\n",
        "        args.augment_args.tune_heuristic = 'rt' # enable ada heuristic\n",
        "        args.augment_args.pop('apply_func', None) # disable discriminator augmentation\n",
        "        args.augment_args.pop('apply_args', None)\n",
        "        args.augment_args.tune_target = 0.95\n",
        "\n",
        "    elif cmethod == 'wgangp':\n",
        "        if aug != 'noaug':\n",
        "            raise UserError(f'--cmethod={cmethod} is not compatible with discriminator augmentation; please specify --aug=noaug')\n",
        "        if gamma is not None:\n",
        "            raise UserError(f'--cmethod={cmethod} is not compatible with --gamma')\n",
        "        args.loss_args = dnnlib.EasyDict(func_name='training.loss.wgangp')\n",
        "        args.G_opt_args.learning_rate = args.D_opt_args.learning_rate = 0.001\n",
        "        args.G_args.num_fp16_res = args.D_args.num_fp16_res = 0 # disable mixed-precision training\n",
        "        args.G_args.conv_clamp = args.D_args.conv_clamp = None\n",
        "        args.lazy_regularization = False\n",
        "\n",
        "    elif cmethod == 'auxrot':\n",
        "        if args.train_dataset_args.max_label_size > 0:\n",
        "            raise UserError(f'--cmethod={cmethod} is not compatible with label conditioning; please specify a dataset without labels')\n",
        "        args.loss_args.func_name = 'training.loss.cmethods'\n",
        "        args.loss_args.auxrot_alpha = 10\n",
        "        args.loss_args.auxrot_beta = 5\n",
        "        args.D_args.score_max = 5 # prepare D to output 5 scalars per image instead of just 1\n",
        "\n",
        "    elif cmethod == 'spectralnorm':\n",
        "        args.D_args.use_spectral_norm = True\n",
        "\n",
        "    elif cmethod == 'shallowmap':\n",
        "        if args.G_args.mapping_layers == 2:\n",
        "            raise UserError(f'--cmethod={cmethod} is a no-op for --cfg={cfg}')\n",
        "        args.G_args.mapping_layers = 2\n",
        "\n",
        "    elif cmethod == 'adropout':\n",
        "        if aug != 'noaug':\n",
        "            raise UserError(f'--cmethod={cmethod} is not compatible with discriminator augmentation; please specify --aug=noaug')\n",
        "        args.D_args.adaptive_dropout = 1\n",
        "        args.augment_args.tune_heuristic = 'rt' # enable ada heuristic\n",
        "        args.augment_args.pop('apply_func', None) # disable discriminator augmentation\n",
        "        args.augment_args.pop('apply_args', None)\n",
        "        args.augment_args.tune_target = 0.6\n",
        "\n",
        "    else:\n",
        "        raise UserError(f'--cmethod={cmethod} not supported')\n",
        "\n",
        "    if dcap is not None:\n",
        "        assert isinstance(dcap, float)\n",
        "        if not dcap > 0:\n",
        "            raise UserError('--dcap must be positive')\n",
        "        desc += f'-dcap{dcap:g}'\n",
        "        args.D_args.fmap_base = max(int(args.D_args.fmap_base * dcap), 1)\n",
        "        args.D_args.fmap_max = max(int(args.D_args.fmap_max * dcap), 1)\n",
        "\n",
        "    # ----------------------------------\n",
        "    # Transfer learning: resume, freezed\n",
        "    # ----------------------------------\n",
        "\n",
        "    resume_specs = {\n",
        "        'ffhq256':      'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/transfer-learning-source-nets/ffhq-res256-mirror-paper256-noaug.pkl',\n",
        "        'ffhq512':      'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/transfer-learning-source-nets/ffhq-res512-mirror-stylegan2-noaug.pkl',\n",
        "        'ffhq1024':     'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/transfer-learning-source-nets/ffhq-res1024-mirror-stylegan2-noaug.pkl',\n",
        "        'celebahq256':  'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/transfer-learning-source-nets/celebahq-res256-mirror-paper256-kimg100000-ada-target0.5.pkl',\n",
        "        'lsundog256':   'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/transfer-learning-source-nets/lsundog-res256-paper256-kimg100000-noaug.pkl',\n",
        "    }\n",
        "\n",
        "    assert resume is None or isinstance(resume, str)\n",
        "    if resume is None:\n",
        "        resume = 'noresume'\n",
        "    elif resume == 'noresume':\n",
        "        desc += '-noresume'\n",
        "    elif resume in resume_specs:\n",
        "        desc += f'-resume{resume}'\n",
        "        args.resume_pkl = resume_specs[resume] # predefined url\n",
        "    else:\n",
        "        desc += '-resumecustom'\n",
        "        args.resume_pkl = resume # custom path or url\n",
        "\n",
        "    if resume != 'noresume':\n",
        "        args.augment_args.tune_kimg = 100 # make ADA react faster at the beginning\n",
        "        args.G_smoothing_rampup = None # disable EMA rampup\n",
        "\n",
        "    if freezed is not None:\n",
        "        assert isinstance(freezed, int)\n",
        "        if not freezed >= 0:\n",
        "            raise UserError('--freezed must be non-negative')\n",
        "        desc += f'-freezed{freezed:d}'\n",
        "        args.D_args.freeze_layers = freezed\n",
        "\n",
        "    return desc, args, outdir\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def run_training():\n",
        "\n",
        "    run_desc, training_options, outdir = setup_training_options()\n",
        "\n",
        "    # Pick output directory.\n",
        "    prev_run_dirs = []\n",
        "    if os.path.isdir(outdir):\n",
        "        prev_run_dirs = [x for x in os.listdir(outdir) if os.path.isdir(os.path.join(outdir, x))]\n",
        "    prev_run_ids = [re.match(r'^\\d+', x) for x in prev_run_dirs]\n",
        "    prev_run_ids = [int(x.group()) for x in prev_run_ids if x is not None]\n",
        "    cur_run_id = max(prev_run_ids, default=-1) + 1\n",
        "    training_options.run_dir = os.path.join(outdir, f'{cur_run_id:05d}-{run_desc}')\n",
        "    assert not os.path.exists(training_options.run_dir)\n",
        "\n",
        "    # Print options.\n",
        "    print()\n",
        "    print('Training options:')\n",
        "    print(json.dumps(training_options, indent=2))\n",
        "    print()\n",
        "    print(f'Output directory:  {training_options.run_dir}')\n",
        "    print(f'Training data:     {training_options.train_dataset_args.path}')\n",
        "    print(f'Training length:   {training_options.total_kimg} kimg')\n",
        "    print(f'Resolution:        {training_options.train_dataset_args.resolution}')\n",
        "    print(f'Number of GPUs:    {training_options.num_gpus}')\n",
        "    print()\n",
        "\n",
        "    # Kick off training.\n",
        "    print('Creating output directory...')\n",
        "    os.makedirs(training_options.run_dir)\n",
        "    with open(os.path.join(training_options.run_dir, 'training_options.json'), 'wt') as f:\n",
        "        json.dump(training_options, f, indent=2)\n",
        "    with dnnlib.util.Logger(os.path.join(training_options.run_dir, 'log.txt')):\n",
        "        training_loop.training_loop(**training_options)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def _str_to_bool(v):\n",
        "    if isinstance(v, bool):\n",
        "        return v\n",
        "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
        "        return True\n",
        "    if v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
        "        return False\n",
        "    raise argparse.ArgumentTypeError('Boolean value expected.')\n",
        "\n",
        "def _parse_comma_sep(s):\n",
        "    if s is None or s.lower() == 'none' or s == '':\n",
        "        return []\n",
        "    return s.split(',')\n",
        "\n",
        "def main():\n",
        "    run_training()\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "#----------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <function TFRecordDataset.parse_tfrecord_tf at 0x7f631508b4d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_args\": {\n",
            "    \"func_name\": \"training.networks.G_main\",\n",
            "    \"fmap_base\": 16384,\n",
            "    \"fmap_max\": 512,\n",
            "    \"mapping_layers\": 2,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"D_args\": {\n",
            "    \"func_name\": \"training.networks.D_main\",\n",
            "    \"mbstd_group_size\": 4,\n",
            "    \"fmap_base\": 16384,\n",
            "    \"fmap_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_args\": {\n",
            "    \"beta1\": 0.0,\n",
            "    \"beta2\": 0.99,\n",
            "    \"learning_rate\": 0.002\n",
            "  },\n",
            "  \"D_opt_args\": {\n",
            "    \"beta1\": 0.0,\n",
            "    \"beta2\": 0.99,\n",
            "    \"learning_rate\": 0.002\n",
            "  },\n",
            "  \"loss_args\": {\n",
            "    \"func_name\": \"training.loss.stylegan2\",\n",
            "    \"r1_gamma\": 10\n",
            "  },\n",
            "  \"augment_args\": {\n",
            "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
            "    \"tune_heuristic\": \"rt\",\n",
            "    \"tune_target\": 0.6,\n",
            "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
            "    \"apply_args\": {\n",
            "      \"xflip\": 1,\n",
            "      \"rotate90\": 1,\n",
            "      \"xint\": 1,\n",
            "      \"scale\": 1,\n",
            "      \"rotate\": 1,\n",
            "      \"aniso\": 1,\n",
            "      \"xfrac\": 1,\n",
            "      \"brightness\": 1,\n",
            "      \"contrast\": 1,\n",
            "      \"lumaflip\": 1,\n",
            "      \"hue\": 1,\n",
            "      \"saturation\": 1\n",
            "    },\n",
            "    \"tune_kimg\": 100\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 1,\n",
            "  \"network_snapshot_ticks\": 1,\n",
            "  \"train_dataset_args\": {\n",
            "    \"path\": \"/content/datasets/custom/\",\n",
            "    \"max_label_size\": 0,\n",
            "    \"resolution\": 1024,\n",
            "    \"mirror_augment\": true\n",
            "  },\n",
            "  \"metric_arg_list\": [],\n",
            "  \"metric_dataset_args\": {\n",
            "    \"path\": \"/content/datasets/custom/\",\n",
            "    \"max_label_size\": 0,\n",
            "    \"resolution\": 1024,\n",
            "    \"mirror_augment\": true\n",
            "  },\n",
            "  \"total_kimg\": 10000,\n",
            "  \"minibatch_size\": 32,\n",
            "  \"minibatch_gpu\": 4,\n",
            "  \"G_smoothing_kimg\": 10,\n",
            "  \"G_smoothing_rampup\": null,\n",
            "  \"resume_pkl\": \"/content/stylegan2-ffhq-config-f.pkl\",\n",
            "  \"run_dir\": \"/content/drive/My Drive/Colab Notebooks/styleganada-results/00002-custom-mirror-stylegan2-kimg10000-ada-bgc-resumecustom\"\n",
            "}\n",
            "\n",
            "Output directory:  /content/drive/My Drive/Colab Notebooks/styleganada-results/00002-custom-mirror-stylegan2-kimg10000-ada-bgc-resumecustom\n",
            "Training data:     /content/datasets/custom/\n",
            "Training length:   10000 kimg\n",
            "Resolution:        1024\n",
            "Number of GPUs:    1\n",
            "\n",
            "Creating output directory...\n",
            "Loading training set...\n",
            "Image shape: [3, 1024, 1024]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
            "Resuming from \"/content/stylegan2-ffhq-config-f.pkl\"\n",
            "\n",
            "G                               Params    OutputShape          WeightShape     \n",
            "---                             ---       ---                  ---             \n",
            "latents_in                      -         (?, 512)             -               \n",
            "labels_in                       -         (?, 0)               -               \n",
            "G_mapping/Normalize             -         (?, 512)             -               \n",
            "G_mapping/Dense0                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense1                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Broadcast             -         (?, 18, 512)         -               \n",
            "dlatent_avg                     -         (512,)               -               \n",
            "Truncation/Lerp                 -         (?, 18, 512)         -               \n",
            "G_synthesis/4x4/Const           8192      (?, 512, 4, 4)       (1, 512, 4, 4)  \n",
            "G_synthesis/4x4/Conv            2622465   (?, 512, 4, 4)       (3, 3, 512, 512)\n",
            "G_synthesis/4x4/ToRGB           264195    (?, 3, 4, 4)         (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up        2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1           2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Upsample        -         (?, 3, 8, 8)         -               \n",
            "G_synthesis/8x8/ToRGB           264195    (?, 3, 8, 8)         (1, 1, 512, 3)  \n",
            "G_synthesis/16x16/Conv0_up      2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1         2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Upsample      -         (?, 3, 16, 16)       -               \n",
            "G_synthesis/16x16/ToRGB         264195    (?, 3, 16, 16)       (1, 1, 512, 3)  \n",
            "G_synthesis/32x32/Conv0_up      2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1         2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Upsample      -         (?, 3, 32, 32)       -               \n",
            "G_synthesis/32x32/ToRGB         264195    (?, 3, 32, 32)       (1, 1, 512, 3)  \n",
            "G_synthesis/64x64/Conv0_up      2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Conv1         2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Upsample      -         (?, 3, 64, 64)       -               \n",
            "G_synthesis/64x64/ToRGB         264195    (?, 3, 64, 64)       (1, 1, 512, 3)  \n",
            "G_synthesis/128x128/Conv0_up    1442561   (?, 256, 128, 128)   (3, 3, 512, 256)\n",
            "G_synthesis/128x128/Conv1       721409    (?, 256, 128, 128)   (3, 3, 256, 256)\n",
            "G_synthesis/128x128/Upsample    -         (?, 3, 128, 128)     -               \n",
            "G_synthesis/128x128/ToRGB       132099    (?, 3, 128, 128)     (1, 1, 256, 3)  \n",
            "G_synthesis/256x256/Conv0_up    426369    (?, 128, 256, 256)   (3, 3, 256, 128)\n",
            "G_synthesis/256x256/Conv1       213249    (?, 128, 256, 256)   (3, 3, 128, 128)\n",
            "G_synthesis/256x256/Upsample    -         (?, 3, 256, 256)     -               \n",
            "G_synthesis/256x256/ToRGB       66051     (?, 3, 256, 256)     (1, 1, 128, 3)  \n",
            "G_synthesis/512x512/Conv0_up    139457    (?, 64, 512, 512)    (3, 3, 128, 64) \n",
            "G_synthesis/512x512/Conv1       69761     (?, 64, 512, 512)    (3, 3, 64, 64)  \n",
            "G_synthesis/512x512/Upsample    -         (?, 3, 512, 512)     -               \n",
            "G_synthesis/512x512/ToRGB       33027     (?, 3, 512, 512)     (1, 1, 64, 3)   \n",
            "G_synthesis/1024x1024/Conv0_up  51297     (?, 32, 1024, 1024)  (3, 3, 64, 32)  \n",
            "G_synthesis/1024x1024/Conv1     25665     (?, 32, 1024, 1024)  (3, 3, 32, 32)  \n",
            "G_synthesis/1024x1024/Upsample  -         (?, 3, 1024, 1024)   -               \n",
            "G_synthesis/1024x1024/ToRGB     16515     (?, 3, 1024, 1024)   (1, 1, 32, 3)   \n",
            "---                             ---       ---                  ---             \n",
            "Total                           28794124                                       \n",
            "\n",
            "\n",
            "D                     Params    OutputShape          WeightShape     \n",
            "---                   ---       ---                  ---             \n",
            "images_in             -         (?, 3, 1024, 1024)   -               \n",
            "labels_in             -         (?, 0)               -               \n",
            "1024x1024/FromRGB     128       (?, 32, 1024, 1024)  (1, 1, 3, 32)   \n",
            "1024x1024/Conv0       9248      (?, 32, 1024, 1024)  (3, 3, 32, 32)  \n",
            "1024x1024/Conv1_down  18496     (?, 64, 512, 512)    (3, 3, 32, 64)  \n",
            "1024x1024/Skip        2048      (?, 64, 512, 512)    (1, 1, 32, 64)  \n",
            "512x512/Conv0         36928     (?, 64, 512, 512)    (3, 3, 64, 64)  \n",
            "512x512/Conv1_down    73856     (?, 128, 256, 256)   (3, 3, 64, 128) \n",
            "512x512/Skip          8192      (?, 128, 256, 256)   (1, 1, 64, 128) \n",
            "256x256/Conv0         147584    (?, 128, 256, 256)   (3, 3, 128, 128)\n",
            "256x256/Conv1_down    295168    (?, 256, 128, 128)   (3, 3, 128, 256)\n",
            "256x256/Skip          32768     (?, 256, 128, 128)   (1, 1, 128, 256)\n",
            "128x128/Conv0         590080    (?, 256, 128, 128)   (3, 3, 256, 256)\n",
            "128x128/Conv1_down    1180160   (?, 512, 64, 64)     (3, 3, 256, 512)\n",
            "128x128/Skip          131072    (?, 512, 64, 64)     (1, 1, 256, 512)\n",
            "64x64/Conv0           2359808   (?, 512, 64, 64)     (3, 3, 512, 512)\n",
            "64x64/Conv1_down      2359808   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "64x64/Skip            262144    (?, 512, 32, 32)     (1, 1, 512, 512)\n",
            "32x32/Conv0           2359808   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "32x32/Conv1_down      2359808   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "32x32/Skip            262144    (?, 512, 16, 16)     (1, 1, 512, 512)\n",
            "16x16/Conv0           2359808   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "16x16/Conv1_down      2359808   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "16x16/Skip            262144    (?, 512, 8, 8)       (1, 1, 512, 512)\n",
            "8x8/Conv0             2359808   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "8x8/Conv1_down        2359808   (?, 512, 4, 4)       (3, 3, 512, 512)\n",
            "8x8/Skip              262144    (?, 512, 4, 4)       (1, 1, 512, 512)\n",
            "4x4/MinibatchStddev   -         (?, 513, 4, 4)       -               \n",
            "4x4/Conv              2364416   (?, 512, 4, 4)       (3, 3, 513, 512)\n",
            "4x4/Dense0            4194816   (?, 512)             (8192, 512)     \n",
            "Output                513       (?, 1)               (512, 1)        \n",
            "---                   ---       ---                  ---             \n",
            "Total                 29012513                                       \n",
            "\n",
            "Exporting sample images...\n",
            "Replicating networks across 1 GPUs...\n",
            "Initializing augmentations...\n",
            "Setting up optimizers...\n",
            "Constructing training graph...\n",
            "Finalizing training ops...\n",
            "Initializing metrics...\n",
            "Training for 10000 kimg...\n",
            "\n",
            "tick 0     kimg 0.1      time 3m 03s       sec/tick 84.0    sec/kimg 655.99  maintenance 99.1   gpumem 10.1  augment 0.000\n",
            "tick 1     kimg 10.2     time 1h 24m 45s   sec/tick 4873.8  sec/kimg 481.98  maintenance 27.9   gpumem 10.1  augment 0.088\n",
            "tick 2     kimg 20.4     time 2h 47m 09s   sec/tick 4927.8  sec/kimg 487.32  maintenance 15.9   gpumem 10.1  augment 0.182\n",
            "tick 3     kimg 30.5     time 4h 10m 07s   sec/tick 4963.2  sec/kimg 490.83  maintenance 15.3   gpumem 10.1  augment 0.268\n",
            "tick 4     kimg 40.6     time 5h 33m 43s   sec/tick 5000.7  sec/kimg 494.53  maintenance 15.2   gpumem 10.1  augment 0.358\n",
            "tick 5     kimg 50.7     time 6h 57m 46s   sec/tick 5027.7  sec/kimg 497.21  maintenance 14.9   gpumem 10.1  augment 0.403\n",
            "tick 6     kimg 60.8     time 8h 21m 44s   sec/tick 5022.5  sec/kimg 496.68  maintenance 15.5   gpumem 10.1  augment 0.302\n",
            "tick 7     kimg 70.9     time 9h 45m 11s   sec/tick 4990.4  sec/kimg 493.51  maintenance 17.2   gpumem 10.1  augment 0.275\n",
            "tick 8     kimg 81.0     time 11h 08m 58s  sec/tick 5008.8  sec/kimg 495.33  maintenance 18.2   gpumem 10.1  augment 0.369\n",
            "tick 9     kimg 91.1     time 12h 33m 04s  sec/tick 5028.4  sec/kimg 497.27  maintenance 17.0   gpumem 10.1  augment 0.462\n",
            "tick 10    kimg 101.2    time 13h 57m 51s  sec/tick 5071.4  sec/kimg 501.52  maintenance 15.8   gpumem 10.1  augment 0.538\n",
            "tick 11    kimg 111.4    time 15h 23m 02s  sec/tick 5095.7  sec/kimg 503.93  maintenance 15.0   gpumem 10.1  augment 0.600\n",
            "tick 12    kimg 121.5    time 16h 48m 32s  sec/tick 5116.1  sec/kimg 505.94  maintenance 14.7   gpumem 10.1  augment 0.668\n",
            "tick 13    kimg 131.6    time 18h 14m 18s  sec/tick 5131.0  sec/kimg 507.42  maintenance 14.9   gpumem 10.1  augment 0.721\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e88632069e30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;31m#----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-e88632069e30>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m     \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;31m#----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-e88632069e30>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mdnnlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'log.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mtraining_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtraining_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;31m#----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/stylegan2-ada/training/training_loop.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(run_dir, G_args, D_args, G_opt_args, D_opt_args, loss_args, train_dataset_args, metric_dataset_args, augment_args, metric_arg_list, num_gpus, minibatch_size, minibatch_gpu, G_smoothing_kimg, G_smoothing_rampup, minibatch_repeats, lazy_regularization, G_reg_interval, D_reg_interval, total_kimg, kimg_per_tick, image_snapshot_ticks, network_snapshot_ticks, resume_pkl, resume_kimg, resume_time, abort_fn, progress_fn)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_round\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrounds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                     \u001b[0mtflib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_train_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mrun_G_reg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                         \u001b[0mtflib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_reg_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/stylegan2-ada/dnnlib/tflib/tfutil.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;34m\"\"\"Run the specified ops in the default session.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0massert_tf_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52yQNwe670aw"
      },
      "source": [
        "# Visualise training process using a timelapse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr7RMG39G7RN"
      },
      "source": [
        "import cv2\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from google.colab import files\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import imageio\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NHQxlck8n5E"
      },
      "source": [
        "result_path = '/content/drive/MyDrive/styleganada-results/'\n",
        "image_files = [f for f in listdir(result_path)]\n",
        "image_files = [f for f in image_files if '.png' in f]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a3OlNJpzGuy"
      },
      "source": [
        "images = []\n",
        "\n",
        "width = 256\n",
        "width_images = 8\n",
        "width_offset = 0 * width\n",
        "end_width = np.max(2048, width_images * width) \n",
        "\n",
        "height = 256\n",
        "height_images = 4\n",
        "height_offset = 0 * height\n",
        "end_height = np.max(1280, height_images * height)\n",
        "\n",
        "\n",
        "for f in tqdm(image_files[:4]):\n",
        "  name = \"{}{}\".format(result_path, f)\n",
        "  print(name)\n",
        "  img = Image.open(name)\n",
        "  img = img.crop((0, 0, end_width+ width_offset, end_height + height_offset))\n",
        "  img = img.resize((1920,1080))\n",
        "  images.append(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bnVYcAS-BN0"
      },
      "source": [
        "try:\n",
        "  os.mkdir(\"/content/out/\")\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp0lejMIAd8i"
      },
      "source": [
        "# Generating using Stylegan2-ada\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZALLoAw_A4wm"
      },
      "source": [
        "# Download the model of choice\n",
        "import argparse\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import re\n",
        "import sys\n",
        "from io import BytesIO\n",
        "import IPython.display\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "from PIL import Image, ImageDraw\n",
        "import imageio\n",
        "import os\n",
        "import pickle\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub5iR_SMzJpD"
      },
      "source": [
        "%cd /content/stylegan2-ada/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xHFjhrpzK0S"
      },
      "source": [
        "dnnlib.tflib.init_tf()\n",
        "network_pkl = '/content/stylegan2-ffhq-config-f.pkl'\n",
        " \n",
        "print('Loading networks from \"%s\"...' % network_pkl)\n",
        "with dnnlib.util.open_url(network_pkl) as fp:\n",
        "    _G, _D, Gs = pickle.load(fp)\n",
        "noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhpkMn-sBA1o"
      },
      "source": [
        "# Useful utility functions...\n",
        "\n",
        "# Generates a list of images, based on a list of latent vectors (Z), and a list (or a single constant) of truncation_psi's.\n",
        "def generate_images_in_w_space(dlatents, truncation_psi):\n",
        "    Gs_kwargs = dnnlib.EasyDict()\n",
        "    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_kwargs.randomize_noise = False\n",
        "    Gs_kwargs.truncation_psi = truncation_psi\n",
        "    dlatent_avg = Gs.get_var('dlatent_avg') # [component]\n",
        "\n",
        "    imgs = []\n",
        "    for row, dlatent in log_progress(enumerate(dlatents), name = \"Generating images\"):\n",
        "        #row_dlatents = (dlatent[np.newaxis] - dlatent_avg) * np.reshape(truncation_psi, [-1, 1, 1]) + dlatent_avg\n",
        "        dl = (dlatent-dlatent_avg)*truncation_psi   + dlatent_avg\n",
        "        row_images = Gs.components.synthesis.run(dlatent,  **Gs_kwargs)\n",
        "        imgs.append(PIL.Image.fromarray(row_images[0], 'RGB'))\n",
        "    return imgs       \n",
        "\n",
        "def generate_images(zs, truncation_psi):\n",
        "    Gs_kwargs = dnnlib.EasyDict()\n",
        "    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_kwargs.randomize_noise = False\n",
        "    if not isinstance(truncation_psi, list):\n",
        "        truncation_psi = [truncation_psi] * len(zs)\n",
        "        \n",
        "    imgs = []\n",
        "    for z_idx, z in log_progress(enumerate(zs), size = len(zs), name = \"Generating images\"):\n",
        "        Gs_kwargs.truncation_psi = truncation_psi[z_idx]\n",
        "        noise_rnd = np.random.RandomState(1) # fix noise\n",
        "        tflib.set_vars({var: noise_rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\n",
        "        images = Gs.run(z, None, **Gs_kwargs) # [minibatch, height, width, channel]\n",
        "        imgs.append(PIL.Image.fromarray(images[0], 'RGB'))\n",
        "    return imgs\n",
        "\n",
        "def generate_zs_from_seeds(seeds):\n",
        "    zs = []\n",
        "    for seed_idx, seed in enumerate(seeds):\n",
        "        rnd = np.random.RandomState(seed)\n",
        "        z = rnd.randn(1, *Gs.input_shape[1:]) # [minibatch, component]\n",
        "        zs.append(z)\n",
        "    return zs\n",
        "\n",
        "# Generates a list of images, based on a list of seed for latent vectors (Z), and a list (or a single constant) of truncation_psi's.\n",
        "def generate_images_from_seeds(seeds, truncation_psi):\n",
        "    return generate_images(generate_zs_from_seeds(seeds), truncation_psi)\n",
        "\n",
        "def saveImgs(imgs, location):\n",
        "  for idx, img in log_progress(enumerate(imgs), size = len(imgs), name=\"Saving images\"):\n",
        "    file = location+ str(idx) + \".png\"\n",
        "    img.save(file)\n",
        "\n",
        "def imshow(a, format='png', jpeg_fallback=True):\n",
        "  a = np.asarray(a, dtype=np.uint8)\n",
        "  str_file = BytesIO()\n",
        "  PIL.Image.fromarray(a).save(str_file, format)\n",
        "  im_data = str_file.getvalue()\n",
        "  try:\n",
        "    disp = IPython.display.display(IPython.display.Image(im_data))\n",
        "  except IOError:\n",
        "    if jpeg_fallback and format != 'jpeg':\n",
        "      print ('Warning: image was too large to display in format \"{}\"; '\n",
        "             'trying jpeg instead.').format(format)\n",
        "      return imshow(a, format='jpeg')\n",
        "    else:\n",
        "      raise\n",
        "  return disp\n",
        "\n",
        "def showarray(a, fmt='png'):\n",
        "    a = np.uint8(a)\n",
        "    f = StringIO()\n",
        "    PIL.Image.fromarray(a).save(f, fmt)\n",
        "    IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
        "\n",
        "        \n",
        "def clamp(x, minimum, maximum):\n",
        "    return max(minimum, min(x, maximum))\n",
        "    \n",
        "def drawLatent(image,latents,x,y,x2,y2, color=(255,0,0,100)):\n",
        "  buffer = PIL.Image.new('RGBA', image.size, (0,0,0,0))\n",
        "   \n",
        "  draw = ImageDraw.Draw(buffer)\n",
        "  cy = (y+y2)/2\n",
        "  draw.rectangle([x,y,x2,y2],fill=(255,255,255,180), outline=(0,0,0,180))\n",
        "  for i in range(len(latents)):\n",
        "    mx = x + (x2-x)*(float(i)/len(latents))\n",
        "    h = (y2-y)*latents[i]*0.1\n",
        "    h = clamp(h,cy-y2,y2-cy)\n",
        "    draw.line((mx,cy,mx,cy+h),fill=color)\n",
        "  return PIL.Image.alpha_composite(image,buffer)\n",
        "             \n",
        "  \n",
        "def createImageGrid(images, scale=0.25, rows=1):\n",
        "   w,h = images[0].size\n",
        "   w = int(w*scale)\n",
        "   h = int(h*scale)\n",
        "   height = rows*h\n",
        "   cols = ceil(len(images) / rows)\n",
        "   width = cols*w\n",
        "   canvas = PIL.Image.new('RGBA', (width,height), 'white')\n",
        "   for i,img in enumerate(images):\n",
        "     img = img.resize((w,h), PIL.Image.ANTIALIAS)\n",
        "     canvas.paste(img, (w*(i % cols), h*(i // cols))) \n",
        "   return canvas\n",
        "\n",
        "def convertZtoW(latent, truncation_psi=0.7, truncation_cutoff=9):\n",
        "  dlatent = Gs.components.mapping.run(latent, None) # [seed, layer, component]\n",
        "  dlatent_avg = Gs.get_var('dlatent_avg') # [component]\n",
        "  for i in range(truncation_cutoff):\n",
        "    dlatent[0][i] = (dlatent[0][i]-dlatent_avg)*truncation_psi + dlatent_avg\n",
        "    \n",
        "  return dlatent\n",
        "\n",
        "def interpolate(zs, steps):\n",
        "   out = []\n",
        "   for i in range(len(zs)-1):\n",
        "    for index in range(steps):\n",
        "     fraction = index/float(steps) \n",
        "     out.append(zs[i+1]*fraction + zs[i]*(1-fraction))\n",
        "   return out\n",
        "\n",
        "# Taken from https://github.com/alexanderkuk/log-progress\n",
        "def log_progress(sequence, every=1, size=None, name='Items'):\n",
        "    from ipywidgets import IntProgress, HTML, VBox\n",
        "    from IPython.display import display\n",
        "\n",
        "    is_iterator = False\n",
        "    if size is None:\n",
        "        try:\n",
        "            size = len(sequence)\n",
        "        except TypeError:\n",
        "            is_iterator = True\n",
        "    if size is not None:\n",
        "        if every is None:\n",
        "            if size <= 200:\n",
        "                every = 1\n",
        "            else:\n",
        "                every = int(size / 200)     # every 0.5%\n",
        "    else:\n",
        "        assert every is not None, 'sequence is iterator, set every'\n",
        "\n",
        "    if is_iterator:\n",
        "        progress = IntProgress(min=0, max=1, value=1)\n",
        "        progress.bar_style = 'info'\n",
        "    else:\n",
        "        progress = IntProgress(min=0, max=size, value=0)\n",
        "    label = HTML()\n",
        "    box = VBox(children=[label, progress])\n",
        "    display(box)\n",
        "\n",
        "    index = 0\n",
        "    try:\n",
        "        for index, record in enumerate(sequence, 1):\n",
        "            if index == 1 or index % every == 0:\n",
        "                if is_iterator:\n",
        "                    label.value = '{name}: {index} / ?'.format(\n",
        "                        name=name,\n",
        "                        index=index\n",
        "                    )\n",
        "                else:\n",
        "                    progress.value = index\n",
        "                    label.value = u'{name}: {index} / {size}'.format(\n",
        "                        name=name,\n",
        "                        index=index,\n",
        "                        size=size\n",
        "                    )\n",
        "            yield record\n",
        "    except:\n",
        "        progress.bar_style = 'danger'\n",
        "        raise\n",
        "    else:\n",
        "        progress.bar_style = 'success'\n",
        "        progress.value = index\n",
        "        label.value = \"{name}: {index}\".format(\n",
        "            name=name,\n",
        "            index=str(index or '?')\n",
        "        )\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIJjA2AhzM6I"
      },
      "source": [
        "imshow(generate_images_from_seeds(np.random.randint(4294967295, size=1), truncation_psi=0.5)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLJHlihazN85"
      },
      "source": [
        "seeds = np.random.randint((2**32 - 1), size=9)\n",
        "imshow(createImageGrid(generate_images_from_seeds(seeds, 0.7), 0.7 , 3))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}